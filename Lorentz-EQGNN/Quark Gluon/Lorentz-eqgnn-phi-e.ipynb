{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140de572",
   "metadata": {
    "id": "rB_xvk_TXLpz",
    "papermill": {
     "duration": 0.013336,
     "end_time": "2024-10-25T09:12:03.935939",
     "exception": false,
     "start_time": "2024-10-25T09:12:03.922603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lorentz-Equivariant Quantum Graph Neural Network (Lorentz-EQGNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c8bb72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:12:03.962380Z",
     "iopub.status.busy": "2024-10-25T09:12:03.961928Z",
     "iopub.status.idle": "2024-10-25T09:12:18.106167Z",
     "shell.execute_reply": "2024-10-25T09:12:18.104865Z"
    },
    "id": "1qx2qWQoXLp2",
    "outputId": "15e852ad-282a-4d36-e400-53399d904f45",
    "papermill": {
     "duration": 14.160956,
     "end_time": "2024-10-25T09:12:18.108772",
     "exception": false,
     "start_time": "2024-10-25T09:12:03.947816",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\r\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.9.5)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2024.6.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.4)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.26.4)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (5.9.3)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (4.66.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (4.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (2024.8.30)\r\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\r\n",
      "Successfully installed torch_geometric-2.6.1\r\n"
     ]
    }
   ],
   "source": [
    "# For Colab\n",
    "!pip install torch_geometric\n",
    "# !pip install torch_sparse\n",
    "# !pip install torch_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1b9d40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:12:18.136287Z",
     "iopub.status.busy": "2024-10-25T09:12:18.135355Z",
     "iopub.status.idle": "2024-10-25T09:12:45.657647Z",
     "shell.execute_reply": "2024-10-25T09:12:45.656365Z"
    },
    "id": "_CF_l60hp0xJ",
    "outputId": "afb90877-280c-44bc-a443-4bb69afffde4",
    "papermill": {
     "duration": 27.538852,
     "end_time": "2024-10-25T09:12:45.660302",
     "exception": false,
     "start_time": "2024-10-25T09:12:18.121450",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pennylane\r\n",
      "  Downloading PennyLane-0.38.0-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Collecting qiskit\r\n",
      "  Downloading qiskit-1.2.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting pennylane-qiskit\r\n",
      "  Downloading PennyLane_qiskit-0.38.1-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Collecting pylatexenc\r\n",
      "  Downloading pylatexenc-2.10.tar.gz (162 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0 in /opt/conda/lib/python3.10/site-packages (from pennylane) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from pennylane) (1.14.1)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from pennylane) (3.3)\r\n",
      "Collecting rustworkx>=0.14.0 (from pennylane)\r\n",
      "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\r\n",
      "Collecting autograd (from pennylane)\r\n",
      "  Downloading autograd-1.7.0-py3-none-any.whl.metadata (7.5 kB)\r\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from pennylane) (0.10.2)\r\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.10/site-packages (from pennylane) (1.4.4)\r\n",
      "Collecting autoray>=0.6.11 (from pennylane)\r\n",
      "  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: cachetools in /opt/conda/lib/python3.10/site-packages (from pennylane) (4.2.4)\r\n",
      "Collecting pennylane-lightning>=0.38 (from pennylane)\r\n",
      "  Downloading PennyLane_Lightning-0.38.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pennylane) (2.32.3)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from pennylane) (4.12.2)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pennylane) (21.3)\r\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/conda/lib/python3.10/site-packages (from qiskit) (1.12)\r\n",
      "Requirement already satisfied: dill>=0.3 in /opt/conda/lib/python3.10/site-packages (from qiskit) (0.3.8)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from qiskit) (2.9.0.post0)\r\n",
      "Collecting stevedore>=3.0.0 (from qiskit)\r\n",
      "  Downloading stevedore-5.3.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting symengine<0.14,>=0.11 (from qiskit)\r\n",
      "  Downloading symengine-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\r\n",
      "Collecting qiskit-aer (from pennylane-qiskit)\r\n",
      "  Downloading qiskit_aer-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\r\n",
      "Collecting qiskit-ibm-runtime<=0.29 (from pennylane-qiskit)\r\n",
      "  Downloading qiskit_ibm_runtime-0.29.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting qiskit-ibm-provider (from pennylane-qiskit)\r\n",
      "  Downloading qiskit_ibm_provider-0.11.0-py3-none-any.whl.metadata (7.6 kB)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\r\n",
      "Collecting requests-ntlm>=1.1.0 (from qiskit-ibm-runtime<=0.29->pennylane-qiskit)\r\n",
      "  Downloading requests_ntlm-1.3.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibm-runtime<=0.29->pennylane-qiskit) (1.26.18)\r\n",
      "Requirement already satisfied: websocket-client>=1.5.1 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibm-runtime<=0.29->pennylane-qiskit) (1.8.0)\r\n",
      "Collecting ibm-platform-services>=0.22.6 (from qiskit-ibm-runtime<=0.29->pennylane-qiskit)\r\n",
      "  Downloading ibm_platform_services-0.58.0-py3-none-any.whl.metadata (9.0 kB)\r\n",
      "Requirement already satisfied: pydantic>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.9.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (3.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pennylane) (2024.8.30)\r\n",
      "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\r\n",
      "  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.3->qiskit) (1.3.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->pennylane) (3.1.2)\r\n",
      "Requirement already satisfied: psutil>=5 in /opt/conda/lib/python3.10/site-packages (from qiskit-aer->pennylane-qiskit) (5.9.3)\r\n",
      "Requirement already satisfied: websockets>=10.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibm-provider->pennylane-qiskit) (12.0)\r\n",
      "Collecting ibm-cloud-sdk-core<4.0.0,>=3.22.0 (from ibm-platform-services>=0.22.6->qiskit-ibm-runtime<=0.29->pennylane-qiskit)\r\n",
      "  Downloading ibm_cloud_sdk_core-3.22.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.5.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.5.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.23.4)\r\n",
      "Requirement already satisfied: cryptography>=1.3 in /opt/conda/lib/python3.10/site-packages (from requests-ntlm>=1.1.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (42.0.8)\r\n",
      "Collecting pyspnego>=0.4.0 (from requests-ntlm>=1.1.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit)\r\n",
      "  Downloading pyspnego-0.11.1-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (1.16.0)\r\n",
      "Collecting urllib3>=1.21.1 (from qiskit-ibm-runtime<=0.29->pennylane-qiskit)\r\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from ibm-cloud-sdk-core<4.0.0,>=3.22.0->ibm-platform-services>=0.22.6->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.8.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.22)\r\n",
      "Downloading PennyLane-0.38.0-py3-none-any.whl (1.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading qiskit-1.2.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading PennyLane_qiskit-0.38.1-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autoray-0.7.0-py3-none-any.whl (930 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading PennyLane_Lightning-0.38.0-cp310-cp310-manylinux_2_28_x86_64.whl (15.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading qiskit_ibm_runtime-0.29.0-py3-none-any.whl (2.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading stevedore-5.3.0-py3-none-any.whl (49 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading symengine-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autograd-1.7.0-py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading qiskit_aer-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading qiskit_ibm_provider-0.11.0-py3-none-any.whl (249 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.9/249.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ibm_platform_services-0.58.0-py3-none-any.whl (340 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.7/340.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests_ntlm-1.3.0-py3-none-any.whl (6.6 kB)\r\n",
      "Downloading ibm_cloud_sdk_core-3.22.0-py3-none-any.whl (69 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.4/69.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyspnego-0.11.1-py3-none-any.whl (130 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pylatexenc\r\n",
      "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136816 sha256=9739dc9128e736ae81a82ab149ab8886d8628337ce8bb360207f4bdf4eaa7c98\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/31/8b/e09b0386afd80cfc556c00408c9aeea5c35c4d484a9c762fd5\r\n",
      "Successfully built pylatexenc\r\n",
      "Installing collected packages: pylatexenc, urllib3, symengine, rustworkx, pbr, autoray, autograd, stevedore, qiskit, pyspnego, ibm-cloud-sdk-core, requests-ntlm, qiskit-aer, ibm-platform-services, qiskit-ibm-runtime, qiskit-ibm-provider, pennylane-lightning, pennylane, pennylane-qiskit\r\n",
      "  Attempting uninstall: urllib3\r\n",
      "    Found existing installation: urllib3 1.26.18\r\n",
      "    Uninstalling urllib3-1.26.18:\r\n",
      "      Successfully uninstalled urllib3-1.26.18\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.3 which is incompatible.\r\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed autograd-1.7.0 autoray-0.7.0 ibm-cloud-sdk-core-3.22.0 ibm-platform-services-0.58.0 pbr-6.1.0 pennylane-0.38.0 pennylane-lightning-0.38.0 pennylane-qiskit-0.38.1 pylatexenc-2.10 pyspnego-0.11.1 qiskit-1.2.4 qiskit-aer-0.15.1 qiskit-ibm-provider-0.11.0 qiskit-ibm-runtime-0.29.0 requests-ntlm-1.3.0 rustworkx-0.15.1 stevedore-5.3.0 symengine-0.13.0 urllib3-2.2.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pennylane qiskit pennylane-qiskit pylatexenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a363ec4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:12:45.699542Z",
     "iopub.status.busy": "2024-10-25T09:12:45.698499Z",
     "iopub.status.idle": "2024-10-25T09:12:51.474522Z",
     "shell.execute_reply": "2024-10-25T09:12:51.473099Z"
    },
    "id": "wITHoRhbp1XM",
    "outputId": "e9f8012a-a11d-4474-fd25-001a585a7b46",
    "papermill": {
     "duration": 5.798309,
     "end_time": "2024-10-25T09:12:51.477157",
     "exception": false,
     "start_time": "2024-10-25T09:12:45.678848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38.0\n",
      "1.2.4\n",
      "0.38.1\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import qiskit\n",
    "print(qml.__version__)\n",
    "print(qiskit.__version__)\n",
    "import pennylane_qiskit\n",
    "print(pennylane_qiskit.__version__)\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "# from pennylane_qiskit import AerDevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1f634d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:12:51.526219Z",
     "iopub.status.busy": "2024-10-25T09:12:51.525284Z",
     "iopub.status.idle": "2024-10-25T09:13:03.996106Z",
     "shell.execute_reply": "2024-10-25T09:13:03.994791Z"
    },
    "id": "VqjY-j8Njo0M",
    "outputId": "1cb36ad8-2f2f-45d3-f9d2-2492b2f455f7",
    "papermill": {
     "duration": 12.502384,
     "end_time": "2024-10-25T09:13:03.998602",
     "exception": false,
     "start_time": "2024-10-25T09:12:51.496218",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting energyflow\r\n",
      "  Downloading EnergyFlow-1.3.2-py2.py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from energyflow) (1.26.4)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from energyflow) (1.16.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from energyflow) (3.11.0)\r\n",
      "Collecting wasserstein>=0.3.1 (from energyflow)\r\n",
      "  Downloading wasserstein-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: wurlitzer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wasserstein>=0.3.1->energyflow) (3.1.1)\r\n",
      "Downloading EnergyFlow-1.3.2-py2.py3-none-any.whl (700 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m700.5/700.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading wasserstein-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (502 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.2/502.2 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: wasserstein, energyflow\r\n",
      "Successfully installed energyflow-1.3.2 wasserstein-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install energyflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad6834c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:04.038220Z",
     "iopub.status.busy": "2024-10-25T09:13:04.037709Z",
     "iopub.status.idle": "2024-10-25T09:13:21.225390Z",
     "shell.execute_reply": "2024-10-25T09:13:21.224207Z"
    },
    "id": "kSESzCxAXLp5",
    "outputId": "61e98bdd-bd95-4736-ff0a-0e8d0d8b974e",
    "papermill": {
     "duration": 17.210635,
     "end_time": "2024-10-25T09:13:21.228142",
     "exception": false,
     "start_time": "2024-10-25T09:13:04.017507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading QG_jets.npz from https://www.dropbox.com/s/fclsl7pukcpobsb/QG_jets.npz?dl=1 to ./data/datasets\n",
      "URL fetch failure on https://www.dropbox.com/s/fclsl7pukcpobsb/QG_jets.npz?dl=1: None -- Bad Request\n",
      "Failed to download QG_jets.npz from source 'dropbox', trying next source...\n",
      "Downloading QG_jets.npz from https://zenodo.org/record/3164691/files/QG_jets.npz?download=1 to ./data/datasets\n",
      "tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]])\n",
      "torch.Size([16]) torch.Size([16, 139, 4]) torch.Size([16, 139, 8]) torch.Size([16, 139]) torch.Size([16, 139, 139]) torch.Size([28736]) torch.Size([28736])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import energyflow\n",
    "from scipy.sparse import coo_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "\n",
    "# we define a function to return an adjacencyy matrix\n",
    "# for our graph data representing the jets.\n",
    "def get_adj_matrix(n_nodes, batch_size, edge_mask):\n",
    "    rows, cols = [], []\n",
    "    # print(edge_mask[0])\n",
    "    # raise\n",
    "    for batch_idx in range(batch_size):\n",
    "        nn = batch_idx*n_nodes\n",
    "        x = coo_matrix(edge_mask[batch_idx])\n",
    "        rows.append(nn + x.row)\n",
    "        cols.append(nn + x.col)\n",
    "    rows = np.concatenate(rows)\n",
    "    cols = np.concatenate(cols)\n",
    "\n",
    "    edges = [torch.LongTensor(rows), torch.LongTensor(cols)]\n",
    "    return edges\n",
    "\n",
    "def collate_fn(data):\n",
    "    data = list(zip(*data)) # label p4s nodes atom_mask\n",
    "    data = [torch.stack(item) for item in data]\n",
    "    batch_size, n_nodes, _ = data[1].size()\n",
    "    atom_mask = data[-1]\n",
    "    edge_mask = atom_mask.unsqueeze(1) * atom_mask.unsqueeze(2)\n",
    "    diag_mask = ~torch.eye(edge_mask.size(1), dtype=torch.bool).unsqueeze(0)\n",
    "    edge_mask *= diag_mask\n",
    "    edges = get_adj_matrix(n_nodes, batch_size, edge_mask)\n",
    "    return data + [edge_mask, edges]\n",
    "\n",
    "def retrieve_dataloaders(batch_size, num_data = -1, use_one_hot = False, cache_dir = './data', num_workers=4):\n",
    "    raw = energyflow.qg_jets.load(num_data=num_data, pad=True, ncol=4, generator='pythia',\n",
    "                            with_bc=False, cache_dir=cache_dir)\n",
    "    splits = ['train', 'val', 'test']\n",
    "    data = {type:{'raw':None,'label':None} for type in splits}\n",
    "    (data['train']['raw'],  data['val']['raw'],   data['test']['raw'],\n",
    "    data['train']['label'], data['val']['label'], data['test']['label']) = \\\n",
    "        energyflow.utils.data_split(*raw, train=0.8, val=0.1, test=0.1, shuffle = False)\n",
    "\n",
    "    enc = OneHotEncoder(handle_unknown='ignore').fit([[11],[13],[22],[130],[211],[321],[2112],[2212]])\n",
    "\n",
    "    for split, value in data.items():\n",
    "        pid = torch.from_numpy(np.abs(np.asarray(value['raw'][...,3], dtype=int))).unsqueeze(-1)\n",
    "        p4s = torch.from_numpy(energyflow.p4s_from_ptyphipids(value['raw'],error_on_unknown=True))\n",
    "        one_hot = enc.transform(pid.reshape(-1,1)).toarray().reshape(pid.shape[:2]+(-1,))\n",
    "        # one_hot = enc.transform(pid.reshape(-1,1)).toarray().reshape(pid.shape[:2]+(-1,))\n",
    "        one_hot = torch.from_numpy(one_hot)\n",
    "        mass = torch.from_numpy(energyflow.ms_from_p4s(p4s)).unsqueeze(-1)\n",
    "        charge = torch.from_numpy(energyflow.pids2chrgs(pid))\n",
    "\n",
    "        if use_one_hot:\n",
    "            nodes = one_hot\n",
    "\n",
    "        # else:\n",
    "        #     nodes = torch.cat((mass,charge),dim=-1)\n",
    "\n",
    "        #     nodes = torch.sign(nodes) * torch.log(torch.abs(nodes) + 1)\n",
    "\n",
    "\n",
    "        else:\n",
    "              # Concatenate mass and charge along the last dimension\n",
    "              concatenated = torch.cat((mass, charge), dim=-1)  # Shape (batch_size, n_nodes, 2)\n",
    "\n",
    "              # Reduce along the last dimension (e.g., by summing or averaging)\n",
    "              nodes = concatenated.sum(dim=-1, keepdim=True)  # Shape (batch_size, n_nodes, 1)\n",
    "\n",
    "              # Apply log-sign transformation if needed\n",
    "              nodes = torch.sign(nodes) * torch.log(torch.abs(nodes) + 1)\n",
    "\n",
    "        atom_mask = (pid[...,0] != 0)\n",
    "\n",
    "        value['p4s'] = p4s\n",
    "        value['nodes'] = nodes\n",
    "        value['label'] = torch.from_numpy(value['label'])\n",
    "        value['atom_mask'] = atom_mask.to(torch.bool)\n",
    "\n",
    "        if split == 'train':\n",
    "            print(value['atom_mask'])\n",
    "\n",
    "    datasets = {split: TensorDataset(value['label'], value['p4s'],\n",
    "                                     value['nodes'], value['atom_mask'])\n",
    "                for split, value in data.items()}\n",
    "\n",
    "    # distributed training\n",
    "    # train_sampler = DistributedSampler(datasets['train'], shuffle=True)\n",
    "    # Construct PyTorch dataloaders from datasets\n",
    "    dataloaders = {split: DataLoader(dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     # sampler=train_sampler if (split == 'train') else DistributedSampler(dataset, shuffle=False),\n",
    "                                     pin_memory=False,\n",
    "                                     # persistent_workers=True,\n",
    "                                     drop_last=True if (split == 'train') else False,\n",
    "                                     num_workers=num_workers,\n",
    "                                     collate_fn=collate_fn)\n",
    "                        for split, dataset in datasets.items()}\n",
    "\n",
    "    return dataloaders #train_sampler, dataloaders\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # train_sampler, dataloaders = retrieve_dataloaders(32, 100)\n",
    "    dataloaders = retrieve_dataloaders(batch_size=16, num_data = 20, use_one_hot = True)\n",
    "    for (label, p4s, nodes, atom_mask, edge_mask, edges) in dataloaders['train']:\n",
    "        print(label.shape, p4s.shape, nodes.shape, atom_mask.shape,\n",
    "              edge_mask.shape, edges[0].shape, edges[1].shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6660d86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:21.270400Z",
     "iopub.status.busy": "2024-10-25T09:13:21.269120Z",
     "iopub.status.idle": "2024-10-25T09:13:21.430651Z",
     "shell.execute_reply": "2024-10-25T09:13:21.429149Z"
    },
    "id": "5I20CB8IXLp6",
    "outputId": "5fbcfdb9-80d8-4630-eda4-c2df78a6407d",
    "papermill": {
     "duration": 0.185189,
     "end_time": "2024-10-25T09:13:21.433128",
     "exception": false,
     "start_time": "2024-10-25T09:13:21.247939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label shape: torch.Size([16])\n",
      "4-momenta shape: torch.Size([16, 139, 4])\n",
      "Node features shape: torch.Size([16, 139, 8])\n",
      "Atom mask shape: torch.Size([16, 139])\n",
      "Edge mask shape: torch.Size([16, 139, 139])\n",
      "Edge indices shapes: torch.Size([28736]), torch.Size([28736])\n"
     ]
    }
   ],
   "source": [
    "# Test the first batch\n",
    "for label, p4s, nodes, atom_mask, edge_mask, edges in dataloaders[\"train\"]:\n",
    "    print(f\"Label shape: {label.shape}\")\n",
    "    print(f\"4-momenta shape: {p4s.shape}\")\n",
    "    print(f\"Node features shape: {nodes.shape}\")\n",
    "    print(f\"Atom mask shape: {atom_mask.shape}\")\n",
    "    print(f\"Edge mask shape: {edge_mask.shape}\")\n",
    "    print(f\"Edge indices shapes: {edges[0].shape}, {edges[1].shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56b11b20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:21.473828Z",
     "iopub.status.busy": "2024-10-25T09:13:21.473029Z",
     "iopub.status.idle": "2024-10-25T09:13:34.340456Z",
     "shell.execute_reply": "2024-10-25T09:13:34.339064Z"
    },
    "id": "SKTo7tNemda4",
    "outputId": "adae491b-4682-45b9-924c-31b85a79279d",
    "papermill": {
     "duration": 12.890474,
     "end_time": "2024-10-25T09:13:34.342734",
     "exception": false,
     "start_time": "2024-10-25T09:13:21.452260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading QG_jets.npz from https://www.dropbox.com/s/fclsl7pukcpobsb/QG_jets.npz?dl=1 to /root/.energyflow/datasets\n",
      "URL fetch failure on https://www.dropbox.com/s/fclsl7pukcpobsb/QG_jets.npz?dl=1: None -- Bad Request\n",
      "Failed to download QG_jets.npz from source 'dropbox', trying next source...\n",
      "Downloading QG_jets.npz from https://zenodo.org/record/3164691/files/QG_jets.npz?download=1 to /root/.energyflow/datasets\n",
      "Saved tensor files to random/data\n",
      "Shapes:\n",
      "p4s: torch.Size([1000, 139, 4])\n",
      "nodes: torch.Size([1000, 139, 1])\n",
      "labels: torch.Size([1000])\n",
      "atom_mask: torch.Size([1000, 139])\n",
      "edge_mask: torch.Size([1000, 139, 139])\n",
      "edges: (2, 2145950)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import energyflow\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def save_physics_tensors(num_data=-1, use_one_hot=False, save_dir=\"random/data\"):\n",
    "    \"\"\"\n",
    "    Generate and save tensor data files needed for physics analysis.\n",
    "\n",
    "    Args:\n",
    "        num_data: Number of data points to generate (-1 for all)\n",
    "        save_dir: Directory to save the tensor files\n",
    "    \"\"\"\n",
    "    # Create save directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Load raw data\n",
    "    raw = energyflow.qg_jets.load(\n",
    "        num_data=num_data,\n",
    "        pad=True,\n",
    "        ncol=4,\n",
    "        generator=\"pythia\",\n",
    "        with_bc=False,\n",
    "    )\n",
    "\n",
    "    # Get data and labels\n",
    "    data, labels = raw\n",
    "\n",
    "    # Initialize one-hot encoder for particle IDs\n",
    "    enc = OneHotEncoder(handle_unknown=\"ignore\").fit(\n",
    "        [[11], [13], [22], [130], [211], [321], [2112], [2212]]\n",
    "    )\n",
    "\n",
    "    # Process data\n",
    "    pid = torch.from_numpy(np.abs(np.asarray(data[..., 3], dtype=int))).unsqueeze(-1)\n",
    "    p4s = torch.from_numpy(energyflow.p4s_from_ptyphipids(data, error_on_unknown=True))\n",
    "\n",
    "    # Create one-hot encoded nodes\n",
    "    one_hot = enc.transform(pid.reshape(-1, 1)).toarray().reshape(pid.shape[:2] + (-1,))\n",
    "    nodes = torch.from_numpy(one_hot)\n",
    "    mass = torch.from_numpy(energyflow.ms_from_p4s(p4s)).unsqueeze(-1)\n",
    "    charge = torch.from_numpy(energyflow.pids2chrgs(pid))\n",
    "\n",
    "    if use_one_hot:\n",
    "        nodes = one_hot\n",
    "\n",
    "    else:\n",
    "          # Concatenate mass and charge along the last dimension\n",
    "          concatenated = torch.cat((mass, charge), dim=-1)  # Shape (batch_size, n_nodes, 2)\n",
    "\n",
    "          # Reduce along the last dimension (e.g., by summing or averaging)\n",
    "          nodes = concatenated.sum(dim=-1, keepdim=True)  # Shape (batch_size, n_nodes, 1)\n",
    "\n",
    "          # Apply log-sign transformation if needed\n",
    "          nodes = torch.sign(nodes) * torch.log(torch.abs(nodes) + 1)\n",
    "\n",
    "    # Create masks\n",
    "    atom_mask = (pid[..., 0] != 0).to(torch.bool)\n",
    "\n",
    "    # Create edge mask\n",
    "    edge_mask = atom_mask.unsqueeze(1) * atom_mask.unsqueeze(2)\n",
    "    diag_mask = ~torch.eye(edge_mask.size(1), dtype=torch.bool).unsqueeze(0)\n",
    "    edge_mask = edge_mask * diag_mask\n",
    "\n",
    "    # Convert labels to tensor\n",
    "    labels = torch.from_numpy(labels)\n",
    "\n",
    "    # Calculate edges for the full dataset\n",
    "    n_nodes = p4s.size(1)\n",
    "    batch_size = p4s.size(0)\n",
    "\n",
    "    rows, cols = [], []\n",
    "    for batch_idx in range(batch_size):\n",
    "        nn = batch_idx * n_nodes\n",
    "        x = coo_matrix(edge_mask[batch_idx])\n",
    "        rows.append(nn + x.row)\n",
    "        cols.append(nn + x.col)\n",
    "    rows = np.concatenate(rows)\n",
    "    cols = np.concatenate(cols)\n",
    "    edges = np.stack([rows, cols])\n",
    "\n",
    "    # Save tensors\n",
    "    torch.save(p4s, os.path.join(save_dir, \"p4s.pt\"))\n",
    "    torch.save(nodes, os.path.join(save_dir, \"nodes.pt\"))\n",
    "    torch.save(labels, os.path.join(save_dir, \"labels.pt\"))\n",
    "    torch.save(atom_mask, os.path.join(save_dir, \"atom_mask.pt\"))\n",
    "    np.save(os.path.join(save_dir, \"edge_mask.npy\"), edge_mask.numpy())\n",
    "    np.save(os.path.join(save_dir, \"edges.npy\"), edges)\n",
    "\n",
    "    print(f\"Saved tensor files to {save_dir}\")\n",
    "    print(f\"Shapes:\")\n",
    "    print(f\"p4s: {p4s.shape}\")\n",
    "    print(f\"nodes: {nodes.shape}\")\n",
    "    print(f\"labels: {labels.shape}\")\n",
    "    print(f\"atom_mask: {atom_mask.shape}\")\n",
    "    print(f\"edge_mask: {edge_mask.shape}\")\n",
    "    print(f\"edges: {edges.shape}\")\n",
    "\n",
    "# Generate and save the tensor files\n",
    "save_physics_tensors(num_data=1000, use_one_hot=False)  # Use same number of data points as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5718a2e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:34.383164Z",
     "iopub.status.busy": "2024-10-25T09:13:34.382135Z",
     "iopub.status.idle": "2024-10-25T09:13:34.414611Z",
     "shell.execute_reply": "2024-10-25T09:13:34.413278Z"
    },
    "id": "bj-Ig4VZXLp6",
    "outputId": "839e7ac0-eeba-4b18-db42-40fcd3d50593",
    "papermill": {
     "duration": 0.055281,
     "end_time": "2024-10-25T09:13:34.417095",
     "exception": false,
     "start_time": "2024-10-25T09:13:34.361814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/1146867464.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  p4s = torch.load('random/data/p4s.pt')\n",
      "/tmp/ipykernel_17/1146867464.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  nodes = torch.load('random/data/nodes.pt')\n",
      "/tmp/ipykernel_17/1146867464.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  labels = torch.load('random/data/labels.pt')\n",
      "/tmp/ipykernel_17/1146867464.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  atom_mask = torch.load('random/data/atom_mask.pt')\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "def get_adj_matrix(n_nodes, batch_size, edge_mask):\n",
    "    rows, cols = [], []\n",
    "    for batch_idx in range(batch_size):\n",
    "        nn = batch_idx*n_nodes\n",
    "        x = coo_matrix(edge_mask[batch_idx])\n",
    "        rows.append(nn + x.row)\n",
    "        cols.append(nn + x.col)\n",
    "    rows = np.concatenate(rows)\n",
    "    cols = np.concatenate(cols)\n",
    "\n",
    "    edges = [torch.LongTensor(rows), torch.LongTensor(cols)]\n",
    "    return edges\n",
    "\n",
    "def collate_fn(data):\n",
    "    data = list(zip(*data)) # label p4s nodes atom_mask\n",
    "    data = [torch.stack(item) for item in data]\n",
    "    batch_size, n_nodes, _ = data[1].size()\n",
    "    atom_mask = data[-1]\n",
    "    # edge_mask = atom_mask.unsqueeze(1) * atom_mask.unsqueeze(2)\n",
    "    # diag_mask = ~torch.eye(edge_mask.size(1), dtype=torch.bool).unsqueeze(0)\n",
    "    # edge_mask *= diag_mask\n",
    "\n",
    "    edge_mask = data[-2]\n",
    "\n",
    "    edges = get_adj_matrix(n_nodes, batch_size, edge_mask)\n",
    "    return data + [edges]\n",
    "\n",
    "\n",
    "p4s = torch.load('random/data/p4s.pt')\n",
    "nodes = torch.load('random/data/nodes.pt')\n",
    "labels = torch.load('random/data/labels.pt')\n",
    "atom_mask = torch.load('random/data/atom_mask.pt')\n",
    "edge_mask = torch.from_numpy(np.load('random/data/edge_mask.npy'))\n",
    "edges = torch.from_numpy(np.load('random/data/edges.npy'))\n",
    "\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset_all = TensorDataset(labels, p4s, nodes, atom_mask, edge_mask)\n",
    "\n",
    "# Define the split ratios\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Calculate the lengths for each split\n",
    "total_size = len(dataset_all)\n",
    "train_size = int(total_size * train_ratio)\n",
    "val_size = int(total_size * val_ratio)\n",
    "test_size = total_size - train_size - val_size  # Ensure all data is used\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset_all, [train_size, val_size, test_size])\n",
    "\n",
    "# Create a dictionary to hold the datasets\n",
    "datasets = {\n",
    "    \"train\": train_dataset,\n",
    "    \"val\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "}\n",
    "\n",
    "dataloaders = {split: DataLoader(dataset,\n",
    "                                 batch_size=16,\n",
    "                                 # sampler=train_sampler if (split == 'train') else DistributedSampler(dataset, shuffle=False),\n",
    "                                 pin_memory=False,\n",
    "                                 # persistent_workers=True,\n",
    "                                 collate_fn = collate_fn,\n",
    "                                 drop_last=True if (split == 'train') else False,\n",
    "                                 num_workers=0)\n",
    "                    for split, dataset in datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a99bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:34.457558Z",
     "iopub.status.busy": "2024-10-25T09:13:34.456471Z",
     "iopub.status.idle": "2024-10-25T09:13:34.461460Z",
     "shell.execute_reply": "2024-10-25T09:13:34.460447Z"
    },
    "id": "dh8IsQXgXLp7",
    "papermill": {
     "duration": 0.027563,
     "end_time": "2024-10-25T09:13:34.463815",
     "exception": false,
     "start_time": "2024-10-25T09:13:34.436252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # we can peek at a batch to see what it looks like.\n",
    "# next(iter(dataloaders['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b80a8a48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:34.503957Z",
     "iopub.status.busy": "2024-10-25T09:13:34.503568Z",
     "iopub.status.idle": "2024-10-25T09:13:34.509606Z",
     "shell.execute_reply": "2024-10-25T09:13:34.508541Z"
    },
    "id": "d5obJPELXLp7",
    "outputId": "8cdc0c11-df10-4e58-c236-b96977e21166",
    "papermill": {
     "duration": 0.028556,
     "end_time": "2024-10-25T09:13:34.511862",
     "exception": false,
     "start_time": "2024-10-25T09:13:34.483306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 139, 4])\n",
      "torch.Size([1000, 139, 1])\n",
      "torch.Size([1000, 139])\n",
      "torch.Size([1000, 139, 139])\n"
     ]
    }
   ],
   "source": [
    "print(p4s.shape) # p4s\n",
    "print(nodes.shape) # mass\n",
    "print(atom_mask.shape) # torch.ones\n",
    "print(edge_mask.shape) # adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e8c3d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:34.552129Z",
     "iopub.status.busy": "2024-10-25T09:13:34.551266Z",
     "iopub.status.idle": "2024-10-25T09:13:34.559594Z",
     "shell.execute_reply": "2024-10-25T09:13:34.558549Z"
    },
    "id": "01O7t2mkXLp8",
    "outputId": "b7e39edc-c3fd-4d52-bdfd-217df4810f63",
    "papermill": {
     "duration": 0.030761,
     "end_time": "2024-10-25T09:13:34.561688",
     "exception": false,
     "start_time": "2024-10-25T09:13:34.530927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x78fc5427ed10>,\n",
       " 'val': <torch.utils.data.dataloader.DataLoader at 0x78fc35fc1e40>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x78fc35fc1de0>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b13a4e65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:34.602591Z",
     "iopub.status.busy": "2024-10-25T09:13:34.601621Z",
     "iopub.status.idle": "2024-10-25T09:13:34.621962Z",
     "shell.execute_reply": "2024-10-25T09:13:34.620700Z"
    },
    "id": "TEs9qVoYXLp8",
    "outputId": "d50c2761-09f4-4212-db8a-3854e4c63354",
    "papermill": {
     "duration": 0.043239,
     "end_time": "2024-10-25T09:13:34.624373",
     "exception": false,
     "start_time": "2024-10-25T09:13:34.581134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shapes:\n",
      "p4s: torch.Size([1000, 139, 4])\n",
      "atom_mask: torch.Size([1000, 139])\n",
      "edge_mask: torch.Size([1000, 139, 139])\n",
      "nodes: torch.Size([1000, 139, 1])\n",
      "\n",
      "After selection shapes:\n",
      "p4s: torch.Size([1, 3, 4])\n",
      "atom_mask: torch.Size([1, 3])\n",
      "edge_mask: torch.Size([1, 3, 3])\n",
      "nodes: torch.Size([1, 3, 1])\n",
      "\n",
      "After reshape shapes:\n",
      "atom_positions: torch.Size([3, 4])\n",
      "atom_mask: torch.Size([3, 1])\n",
      "edge_mask: torch.Size([1, 3, 3])\n",
      "nodes: torch.Size([3, 1])\n",
      "\n",
      "Final shapes:\n",
      "atom_positions: torch.Size([3, 4])\n",
      "atom_mask: torch.Size([3, 1])\n",
      "edge_mask: torch.Size([9, 1])\n",
      "nodes: torch.Size([3, 1])\n",
      "edges: [torch.Size([6]), torch.Size([6])]\n"
     ]
    }
   ],
   "source": [
    "# Set desired dimensions\n",
    "batch_size = 1\n",
    "n_nodes = 3\n",
    "device = 'cpu'\n",
    "dtype = torch.float32\n",
    "\n",
    "# Print initial shapes\n",
    "print(\"Initial shapes:\")\n",
    "print(\"p4s:\", p4s.shape)\n",
    "print(\"atom_mask:\", atom_mask.shape)\n",
    "print(\"edge_mask:\", edge_mask.shape)\n",
    "print(\"nodes:\", nodes.shape)\n",
    "\n",
    "# Select subset of data\n",
    "p4s = p4s[:batch_size, :n_nodes, :]\n",
    "atom_mask = atom_mask[:batch_size, :n_nodes]\n",
    "edge_mask = edge_mask[:batch_size, :n_nodes, :n_nodes]\n",
    "nodes = nodes[:batch_size, :n_nodes, :]\n",
    "\n",
    "print(\"\\nAfter selection shapes:\")\n",
    "print(\"p4s:\", p4s.shape)\n",
    "print(\"atom_mask:\", atom_mask.shape)\n",
    "print(\"edge_mask:\", edge_mask.shape)\n",
    "print(\"nodes:\", nodes.shape)\n",
    "\n",
    "# Reshape tensors\n",
    "atom_positions = p4s.view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "atom_mask = atom_mask.view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "# Don't reshape edge_mask yet\n",
    "nodes = nodes.view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "\n",
    "print(\"\\nAfter reshape shapes:\")\n",
    "print(\"atom_positions:\", atom_positions.shape)\n",
    "print(\"atom_mask:\", atom_mask.shape)\n",
    "print(\"edge_mask:\", edge_mask.shape)  # original shape\n",
    "print(\"nodes:\", nodes.shape)\n",
    "\n",
    "# Recalculate edges for the subset\n",
    "from scipy.sparse import coo_matrix\n",
    "rows, cols = [], []\n",
    "for batch_idx in range(batch_size):\n",
    "    nn = batch_idx * n_nodes\n",
    "    # Convert edge_mask to numpy and remove any extra dimensions\n",
    "    edge_mask_np = edge_mask[batch_idx].cpu().numpy().squeeze()\n",
    "    x = coo_matrix(edge_mask_np)\n",
    "    rows.append(nn + x.row)\n",
    "    cols.append(nn + x.col)\n",
    "\n",
    "edges = [torch.LongTensor(np.concatenate(rows)).to(device),\n",
    "         torch.LongTensor(np.concatenate(cols)).to(device)]\n",
    "\n",
    "# Now reshape edge_mask after edges are calculated\n",
    "edge_mask = edge_mask.reshape(batch_size * n_nodes * n_nodes, -1).to(device)\n",
    "\n",
    "print(\"\\nFinal shapes:\")\n",
    "print(\"atom_positions:\", atom_positions.shape)\n",
    "print(\"atom_mask:\", atom_mask.shape)\n",
    "print(\"edge_mask:\", edge_mask.shape)\n",
    "print(\"nodes:\", nodes.shape)\n",
    "print(\"edges:\", [e.shape for e in edges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73646ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:34.666436Z",
     "iopub.status.busy": "2024-10-25T09:13:34.666029Z",
     "iopub.status.idle": "2024-10-25T09:13:34.673685Z",
     "shell.execute_reply": "2024-10-25T09:13:34.672793Z"
    },
    "id": "dj_AzmjvXLp9",
    "papermill": {
     "duration": 0.031295,
     "end_time": "2024-10-25T09:13:34.675846",
     "exception": false,
     "start_time": "2024-10-25T09:13:34.644551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1  #2500 #1\n",
    "n_nodes = 3 #139\n",
    "device = 'cpu'\n",
    "dtype = torch.float32\n",
    "\n",
    "atom_positions = p4s[:, :, :].view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "\n",
    "atom_mask = atom_mask.view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "edge_mask = edge_mask.reshape(batch_size * n_nodes * n_nodes, -1).to(device)\n",
    "\n",
    "edges = [a.to(device) for a in edges]\n",
    "nodes = nodes.view(batch_size * n_nodes, -1).to(device,dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8c46994",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:34.716799Z",
     "iopub.status.busy": "2024-10-25T09:13:34.716363Z",
     "iopub.status.idle": "2024-10-25T09:13:34.722896Z",
     "shell.execute_reply": "2024-10-25T09:13:34.721810Z"
    },
    "id": "cNq2qPiZKqis",
    "outputId": "8dfa72c5-27b6-467b-83f8-36e2ad8223ea",
    "papermill": {
     "duration": 0.029811,
     "end_time": "2024-10-25T09:13:34.725293",
     "exception": false,
     "start_time": "2024-10-25T09:13:34.695482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final shapes:\n",
      "atom_positions: torch.Size([3, 4])\n",
      "atom_mask: torch.Size([3, 1])\n",
      "edge_mask: torch.Size([9, 1])\n",
      "nodes: torch.Size([3, 1])\n",
      "edges: [torch.Size([6]), torch.Size([6])]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal shapes:\")\n",
    "print(\"atom_positions:\", atom_positions.shape)\n",
    "print(\"atom_mask:\", atom_mask.shape)\n",
    "print(\"edge_mask:\", edge_mask.shape)\n",
    "print(\"nodes:\", nodes.shape)\n",
    "print(\"edges:\", [e.shape for e in edges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accadd0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:34.766190Z",
     "iopub.status.busy": "2024-10-25T09:13:34.765695Z",
     "iopub.status.idle": "2024-10-25T09:13:34.781591Z",
     "shell.execute_reply": "2024-10-25T09:13:34.780405Z"
    },
    "id": "NQhDkqAQXLp9",
    "outputId": "c503537a-d0bd-4cdf-db50-825746d3eb2d",
    "papermill": {
     "duration": 0.039195,
     "end_time": "2024-10-25T09:13:34.783933",
     "exception": false,
     "start_time": "2024-10-25T09:13:34.744738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_mask[0]#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f75f5f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:34.825625Z",
     "iopub.status.busy": "2024-10-25T09:13:34.825209Z",
     "iopub.status.idle": "2024-10-25T09:13:34.833113Z",
     "shell.execute_reply": "2024-10-25T09:13:34.832039Z"
    },
    "id": "zTcu7crAXLp9",
    "outputId": "e5c5698d-9e54-4c0f-9b24-883312b1485d",
    "papermill": {
     "duration": 0.03122,
     "end_time": "2024-10-25T09:13:34.835293",
     "exception": false,
     "start_time": "2024-10-25T09:13:34.804073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1594, -0.2378, -1.1238, -0.0723], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4s[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8521eae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:34.877740Z",
     "iopub.status.busy": "2024-10-25T09:13:34.876567Z",
     "iopub.status.idle": "2024-10-25T09:13:34.883628Z",
     "shell.execute_reply": "2024-10-25T09:13:34.882550Z"
    },
    "id": "TWPwTZmNXLp-",
    "outputId": "33e79a36-7004-4a0d-9eb3-52f1e0646462",
    "papermill": {
     "duration": 0.030717,
     "end_time": "2024-10-25T09:13:34.886042",
     "exception": false,
     "start_time": "2024-10-25T09:13:34.855325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23cc0f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:34.928526Z",
     "iopub.status.busy": "2024-10-25T09:13:34.928133Z",
     "iopub.status.idle": "2024-10-25T09:13:34.935483Z",
     "shell.execute_reply": "2024-10-25T09:13:34.934240Z"
    },
    "id": "dfthGhJ3XLp-",
    "outputId": "ae0d7ad3-8a66-4e80-9aa2-f74f10f7caa4",
    "papermill": {
     "duration": 0.031329,
     "end_time": "2024-10-25T09:13:34.937703",
     "exception": false,
     "start_time": "2024-10-25T09:13:34.906374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4s.shape # batch_size (number of jets or graphs), n_nodes (particles), n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbc6e655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:34.979866Z",
     "iopub.status.busy": "2024-10-25T09:13:34.979448Z",
     "iopub.status.idle": "2024-10-25T09:13:34.989916Z",
     "shell.execute_reply": "2024-10-25T09:13:34.988862Z"
    },
    "id": "fDPOFJnXXLp-",
    "outputId": "cb476565-9a69-4f8e-ffa0-90f75e7a6561",
    "papermill": {
     "duration": 0.034566,
     "end_time": "2024-10-25T09:13:34.992403",
     "exception": false,
     "start_time": "2024-10-25T09:13:34.957837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atom mask: tensor([[1.],\n",
      "        [1.]])\n",
      "Atom positions (x features, 4-momenta): tensor([[ 0.2861,  0.0078, -0.2687,  0.0980],\n",
      "        [ 0.1653, -0.0258, -0.1580, -0.0414]])\n",
      "Nodes (scalars: mass & charge): tensor([[-4.7488e-09],\n",
      "        [-2.2813e-09]])\n",
      "Edge mask: tensor([[False],\n",
      "        [ True]])\n",
      "Edges: [tensor([0, 0, 1, 1, 2, 2]), tensor([1, 2, 0, 2, 0, 1])]\n"
     ]
    }
   ],
   "source": [
    "# random: x(atom_pos), edge_indx_tensor (edges = adj_matrix), edge_tensor (edge_mask = adj_matrix)\n",
    "print(\"Atom mask: {}\".format(atom_mask[:2]))\n",
    "print(\"Atom positions (x features, 4-momenta): {}\".format(atom_positions[:2]))\n",
    "print(\"Nodes (scalars: mass & charge): {}\".format(nodes[:2]))\n",
    "print(\"Edge mask: {}\".format(edge_mask[:2]))\n",
    "print(\"Edges: {}\".format(edges[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3deabd71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:35.035524Z",
     "iopub.status.busy": "2024-10-25T09:13:35.034522Z",
     "iopub.status.idle": "2024-10-25T09:13:35.043033Z",
     "shell.execute_reply": "2024-10-25T09:13:35.041786Z"
    },
    "id": "lDz3-q69XLp-",
    "outputId": "01adc007-56a2-4307-c442-1c4a44f0b14e",
    "papermill": {
     "duration": 0.032151,
     "end_time": "2024-10-25T09:13:35.045126",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.012975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 0, 1, 1, 2, 2]), tensor([1, 2, 0, 2, 0, 1])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges[:2]#[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09e2c17f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:35.087748Z",
     "iopub.status.busy": "2024-10-25T09:13:35.087042Z",
     "iopub.status.idle": "2024-10-25T09:13:35.092171Z",
     "shell.execute_reply": "2024-10-25T09:13:35.090942Z"
    },
    "id": "Ss4oXJjGXLp-",
    "papermill": {
     "duration": 0.028859,
     "end_time": "2024-10-25T09:13:35.094364",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.065505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model(scalars=nodes, x=atom_positions, edges=edges, node_mask=atom_mask,\n",
    "#                          edge_mask=edge_mask, n_nodes=n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9895af5",
   "metadata": {
    "id": "_3cyDPxrXLp-",
    "papermill": {
     "duration": 0.020158,
     "end_time": "2024-10-25T09:13:35.134771",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.114613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. LorentzNet\n",
    "Before delving into the realm of quantum graph neural networks (QGNNs), we shall examine the performance and structure of a very well-known equivariant GNN, **LorentzNet** ([arXiv:2201.08187](https://arxiv.org/abs/2201.08187)), which is classical, on our dataset. Understanding the structure underlying LorentzNet will allow us to understand where to fit in our quantum models, and this will be the heart of our approach.\n",
    "\n",
    "## 3.1. Dataset Representation as Graphs\n",
    "\n",
    "We already discussed this in the introduction, but again, let's remmber that in high-energy particle physics, **jets**—collimated streams of particles resulting from particle collisions—are complex objects that can be naturally represented as graphs. In our dataset:\n",
    "\n",
    "- Each **jet** is modeled as a graph \\( G = (V, E) \\), where:\n",
    "  - $V$ is the set of **nodes**, each corresponding to a constituent particle within the jet.\n",
    "  - $E$ is the set of **edges**, representing interactions or relationships between particles.\n",
    "- Each node (particle) is considered a point in Minkowski space $\\mathbb{R}^{1,3}$, respecting the spacetime symmetries of special relativity.\n",
    "- The number of particles (nodes) varies for each jet, reflecting the stochastic nature of particle collisions.\n",
    "\n",
    "**Reconstructing Four-Momentum Vectors**\n",
    "\n",
    "In practice, particle data may not be directly provided as four-momentum vectors. Instead, they are often given in terms of:\n",
    "\n",
    "- **Transverse Momentum $p_T$**: Momentum perpendicular to the beam axis.\n",
    "- **Pseudo-rapidity $\\eta$**: A spatial coordinate describing the angle of a particle relative to the beam (forward-backward) direction.\n",
    "- **Azimuthal Angle $\\phi$**: Angle around the beam axis in the transverse plane.\n",
    "- **Particle Identification (PID)**: Integer codes representing particle types.\n",
    "\n",
    "**Conversion to Four-Momentum**\n",
    "\n",
    "- Using the relationships:\n",
    "\n",
    "  - $p_x = p_T \\cos\\phi$\n",
    "  - $p_y = p_T \\sin\\phi$\n",
    "  - $p_z = p_T \\sinh\\eta$\n",
    "  - $E = \\sqrt{p_T^2 \\cosh^2\\eta + m^2}$, where $m$ is the particle mass.\n",
    "\n",
    "- The **[EnergyFlow](https://energyflow.network/)** package converts this for us.\n",
    "\n",
    "**Implementation in Code**:\n",
    "\n",
    "- The first step in the data preprocessing involves reconstructing the four-momentum vectors using the available kinematic variables, which is fundamental for us, since:\n",
    "    - First, we want to ensure that the input to LorentzNet is correctly formatted and physically meaningful.\n",
    "    - Also, given the limitations on current quantum hardware, and since we are performing simulations currently, then the number of particles in the jet has to be cut down.\n",
    "\n",
    "## 3.2. Architecture Overview\n",
    "\n",
    "The **LorentzNet** architecture is designed to process and analyze graphs while respecting the **Lorentz symmetry**, a fundamental symmetry in relativistic physics involving rotations and boosts in spacetime (changes in inertial frames).\n",
    "\n",
    "**Key Features of LorentzNet**:\n",
    "\n",
    "- Built upon the **universal approximation theorem** for **Lorentz-equivariant functions**. This theorem ensures that the network can approximate any Lorentz-equivariant function to arbitrary precision, given sufficient capacity.\n",
    "- Incorporates **message passing** mechanisms tailored to respect Lorentz symmetry.\n",
    "- Utilizes **continuous functions** modeled by neural networks to update node and edge features throughout the network layers.\n",
    "\n",
    "**Architecture Diagram**:\n",
    "\n",
    "<center>\n",
    "<img src=\"../figures/LorentzNet.png\" width=\"65%\" style=\"margin-left:auto; margin-right:auto\">\n",
    "</center>\n",
    "\n",
    "*(Figure: Schematic representation of the LorentzNet architecture.)*\n",
    "\n",
    "**Input Layer**\n",
    "\n",
    "The **input** to the LorentzNet consists of:\n",
    "\n",
    "- **Four-momentum vectors** (coordinate embeddings) of particles from collision events.\n",
    "  - Each particle $i$ has a four-momentum $v_i = (E_i, p_{x_i}, p_{y_i}, p_{z_i})$, where:\n",
    "    - $E_i$ is the energy.\n",
    "    - $p_{x_i}, p_{y_i}, p_{z_i}$ are momentum components in three-dimensional space.\n",
    "- **Scalar features** (scalar embeddings) $s_i$ associated with each particle, such as:\n",
    "  - Mass.\n",
    "  - Electric charge.\n",
    "  - Particle identification (PID) codes.\n",
    "\n",
    "The combined feature vector for each particle is:\n",
    "\n",
    "$$\n",
    "f_i = v_i \\oplus s_i,\n",
    "$$\n",
    "\n",
    "where $\\oplus$ denotes concatenation.\n",
    "\n",
    "**Lorentz Group Equivariant Block (LGEB)**\n",
    "\n",
    "At the core of LorentzNet is the **Lorentz Group Equivariant Block (LGEB)**, which updates the features of particles (nodes) and their interactions (edges) while preserving Lorentz equivariance.\n",
    "\n",
    "**The components of LGEB**:\n",
    "\n",
    "1. **Edge Message Function $\\phi_e$**:\n",
    "   - Computes messages passed between particles.\n",
    "   - Captures pairwise interactions and relativistic geometrical relationships.\n",
    "\n",
    "2. **Coordinate Update Function $\\phi_x$**:\n",
    "   - Updates the coordinate embeddings of particles.\n",
    "   - Incorporates attention mechanisms respecting Minkowski spacetime.\n",
    "\n",
    "3. **Scalar Feature Update Function $\\phi_h$**:\n",
    "   - Updates scalar features of particles.\n",
    "   - Aggregates information from neighboring particles.\n",
    "\n",
    "These functions are modeled using neural networks capable of approximating continuous functions.\n",
    "\n",
    "## 3.3. Detailed Formulation\n",
    "\n",
    "1. **Edge Message Computation $\\phi_e$**:\n",
    "\n",
    "   For particles $i$ and $j$ at layer $l$, the **edge message** $m_{ij}^{l}$ is computed as:\n",
    "\n",
    "   $$\n",
    "   m_{ij}^{l} = \\phi_e \\left( h_i^{l}, h_j^{l}, \\psi\\left( \\| x_i^{l} - x_j^{l} \\|^2 \\right), \\psi\\left( \\langle x_i^{l}, x_j^{l} \\rangle \\right) \\right),\n",
    "   $$\n",
    "\n",
    "   where:\n",
    "\n",
    "   - $h_i^{l}$ and $h_j^{l}$ are the scalar features of particles $i$ and $j$ at layer $l$.\n",
    "   - $x_i^{l}$ and $x_j^{l}$ are the coordinate embeddings (four-vectors) at layer $l$.\n",
    "   - $\\| x_i^{l} - x_j^{l} \\|^2$ is the squared Minkowski **distance** between particles $i$ and $j$.\n",
    "   - $\\langle x_i^{l}, x_j^{l} \\rangle$ is the Minkowski **inner product** (Lorentz dot product).\n",
    "   - $\\psi(\\cdot)$ is a normalization function defined as:\n",
    "\n",
    "     $$\n",
    "     \\psi(a) = \\operatorname{sgn}(a) \\cdot \\log\\left( |a| + 1 \\right),\n",
    "     $$\n",
    "\n",
    "     with $\\operatorname{sgn}(a)$ being the sign function.\n",
    "\n",
    "   **Purpose of $\\psi(\\cdot)$**:\n",
    "\n",
    "   - Helps normalize values that may have large magnitudes or come from different distributions.\n",
    "   - Ensures numerical stability during optimization by mapping inputs to a manageable range.\n",
    "\n",
    "\n",
    "2. **Coordinate Embedding Update $\\phi_x$**:\n",
    "\n",
    "   The **coordinate embeddings** of particles are updated via:\n",
    "\n",
    "   $$\n",
    "   x_i^{l+1} = x_i^{l} + c \\sum_{j \\in \\mathcal{N}(i)} \\phi_x ( m_{ij}^{l}) \\cdot x_j^{l},\n",
    "   $$\n",
    "\n",
    "   where:\n",
    "\n",
    "   - $\\mathcal{N}(i)$ denotes the **neighborhood** of particle $i$, i.e., particles connected to $i$ in the graph.\n",
    "   - $c$ is a scaling constant controlling the update magnitude.\n",
    "   - $\\phi_x ( m_{ij}^{l})$ computes an **attention weight** based on the edge message $m_{ij}^{l}$.\n",
    "\n",
    "   **Interpretation**:\n",
    "\n",
    "   - The update adds a weighted sum of neighboring coordinate embeddings $x_j^{l}$ to the current embedding $x_i^{l}$.\n",
    "   - This mechanism allows particles to incorporate spatial information from their neighbors, guided by the learned attention weights.\n",
    "\n",
    "\n",
    "3. **Scalar Feature Update $\\phi_h$**:\n",
    "\n",
    "   The **scalar features** are updated as:\n",
    "\n",
    "   $$\n",
    "   h_i^{l+1} = h_i^{l} + \\phi_h \\left( h_i^{l}, \\sum_{j \\in \\mathcal{N}(i)} w_{ij}^{l} m_{ij}^{l} \\right),\n",
    "   $$\n",
    "\n",
    "   where:\n",
    "\n",
    "   - $w_{ij}^{l}$ is an **edge significance weight** calculated by:\n",
    "\n",
    "     $$\n",
    "     w_{ij}^{l} = \\phi_m \\left( m_{ij}^{l} \\right) \\in [0, 1],\n",
    "     $$\n",
    "\n",
    "     with $\\phi_m$ being a neural network outputting values in the range [0, 1].\n",
    "\n",
    "   - $\\phi_h$ aggregates information from neighboring particles to update $h_i^{l}$.\n",
    "\n",
    "   And for the Purpose of $w_{ij}^{l}$ and $\\phi_h$:\n",
    "\n",
    "   - $w_{ij}^{l}$ signifies the importance of the edge between particles $i$ and $j$.\n",
    "   - $\\phi_h$ integrates these weighted messages to refine the scalar features, enabling the network to learn complex interactions.\n",
    "\n",
    "\n",
    "**Avoiding Redundancy**\n",
    "\n",
    "A noteworthy aspect of LorentzNet is its approach to handling outputs:\n",
    "\n",
    "- Although both **coordinate embeddings** $x_i^{l}$ and **scalar features** $h_i^{l}$ are updated through the layers, the final output only uses the **scalar features** $h_i^{L}$ from the last layer $L$.\n",
    "- This strategy reduces redundancy and computational overhead because:\n",
    "\n",
    "  - The edge messages $m_{ij}^{l}$ already incorporate information from both $x_i^{l}$ and $x_j^{l}$.\n",
    "  - Focusing on scalar features simplifies the network output without losing critical information.\n",
    "\n",
    "      \n",
    "**Implementation Details**\n",
    "\n",
    "To ensure fidelity with the original LorentzNet architecture and leverage existing optimizations, we utilize the official implementation provided by the authors:\n",
    "\n",
    "- **Repository**: [LorentzNet-release](https://github.com/sdogsq/LorentzNet-release/tree/main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a90cf81f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:35.177316Z",
     "iopub.status.busy": "2024-10-25T09:13:35.176906Z",
     "iopub.status.idle": "2024-10-25T09:13:35.211359Z",
     "shell.execute_reply": "2024-10-25T09:13:35.210295Z"
    },
    "id": "49hLoUYRXLp_",
    "papermill": {
     "duration": 0.058925,
     "end_time": "2024-10-25T09:13:35.213893",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.154968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Some auxiliary functions\"\"\"\n",
    "\n",
    "def unsorted_segment_sum(data, segment_ids, num_segments):\n",
    "    r'''Custom PyTorch op to replicate TensorFlow's `unsorted_segment_sum`.\n",
    "    Adapted from https://github.com/vgsatorras/egnn.\n",
    "    '''\n",
    "    result = data.new_zeros((num_segments, data.size(1)))\n",
    "    result.index_add_(0, segment_ids, data)\n",
    "    return result\n",
    "\n",
    "def unsorted_segment_mean(data, segment_ids, num_segments):\n",
    "    r'''Custom PyTorch op to replicate TensorFlow's `unsorted_segment_mean`.\n",
    "    Adapted from https://github.com/vgsatorras/egnn.\n",
    "    '''\n",
    "    result = data.new_zeros((num_segments, data.size(1)))\n",
    "    count = data.new_zeros((num_segments, data.size(1)))\n",
    "    result.index_add_(0, segment_ids, data)\n",
    "    count.index_add_(0, segment_ids, torch.ones_like(data))\n",
    "    return result / count.clamp(min=1)\n",
    "\n",
    "def normsq4(p):\n",
    "    r''' Minkowski square norm\n",
    "         `\\|p\\|^2 = p[0]^2-p[1]^2-p[2]^2-p[3]^2`\n",
    "    '''\n",
    "    psq = torch.pow(p, 2)\n",
    "    return 2 * psq[..., 0] - psq.sum(dim=-1)\n",
    "\n",
    "def dotsq4(p,q):\n",
    "    r''' Minkowski inner product\n",
    "         `<p,q> = p[0]q[0]-p[1]q[1]-p[2]q[2]-p[3]q[3]`\n",
    "    '''\n",
    "    psq = p*q\n",
    "    return 2 * psq[..., 0] - psq.sum(dim=-1)\n",
    "\n",
    "def normA_fn(A):\n",
    "    return lambda p: torch.einsum('...i, ij, ...j->...', p, A, p)\n",
    "\n",
    "def dotA_fn(A):\n",
    "    return lambda p, q: torch.einsum('...i, ij, ...j->...', p, A, q)\n",
    "\n",
    "def psi(p):\n",
    "    ''' `\\psi(p) = Sgn(p) \\cdot \\log(|p| + 1)`\n",
    "    '''\n",
    "    return torch.sign(p) * torch.log(torch.abs(p) + 1)\n",
    "\n",
    "\n",
    "\"\"\"Lorentz Group-Equivariant Block\"\"\"\n",
    "\n",
    "class LGEB(nn.Module):\n",
    "    def __init__(self, n_input, n_output, n_hidden, n_node_attr=0,\n",
    "                 dropout = 0., c_weight=1.0, last_layer=False, A=None, include_x=False):\n",
    "        super(LGEB, self).__init__()\n",
    "        self.c_weight = c_weight\n",
    "        self.dimension_reducer = nn.Linear(10, 4) # New linear layer for dimension reduction\n",
    "        n_edge_attr = 2 if not include_x else 10 # dims for Minkowski norm & inner product\n",
    "        # With include_X = False, not include_x becomes True, so the value of n_edge_attr is 2.\n",
    "        print('Input size of phi_e: ', n_input)\n",
    "\n",
    "        self.include_x = include_x\n",
    "        self.phi_e = nn.Sequential(\n",
    "            nn.Linear(n_input, n_hidden, bias=False), # n_input * 2 + n_edge_attr\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.phi_h = nn.Sequential(\n",
    "            nn.Linear(n_hidden + n_input + n_node_attr, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_output))\n",
    "\n",
    "        layer = nn.Linear(n_hidden, 1, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(layer.weight, gain=0.001)\n",
    "\n",
    "        self.phi_x = nn.Sequential(\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            layer)\n",
    "\n",
    "        self.phi_m = nn.Sequential(\n",
    "            nn.Linear(n_hidden, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "        self.last_layer = last_layer\n",
    "        if last_layer:\n",
    "            del self.phi_x\n",
    "\n",
    "        self.A = A\n",
    "        self.norm_fn = normA_fn(A) if A is not None else normsq4\n",
    "        self.dot_fn = dotA_fn(A) if A is not None else dotsq4\n",
    "\n",
    "\n",
    "    def m_model(self, hi, hj, norms, dots):\n",
    "        out = torch.cat([hi, hj, norms, dots], dim=1)\n",
    "        # Reduce the dimension of 'out' to 4 using a linear layer\n",
    "        out = self.dimension_reducer(out)\n",
    "        out = self.phi_e(out)\n",
    "        # print(\"m_model output: \", out.shape)\n",
    "        w = self.phi_m(out)\n",
    "        out = out * w\n",
    "        return out\n",
    "\n",
    "    def m_model_extended(self, hi, hj, norms, dots, xi, xj):\n",
    "        out = torch.cat([hi, hj, norms, dots, xi, xj], dim=1)\n",
    "        out = self.phi_e(out)\n",
    "        w = self.phi_m(out)\n",
    "        out = out * w\n",
    "        return out\n",
    "\n",
    "    def h_model(self, h, edges, m, node_attr):\n",
    "        i, j = edges\n",
    "        agg = unsorted_segment_sum(m, i, num_segments=h.size(0))\n",
    "        agg = torch.cat([h, agg, node_attr], dim=1)\n",
    "        out = h + self.phi_h(agg)\n",
    "        return out\n",
    "\n",
    "    def x_model(self, x, edges, x_diff, m): # norms\n",
    "        i, j = edges\n",
    "        trans = x_diff * self.phi_x(m)\n",
    "        # print(\"m: \", m.shape)\n",
    "        # print(\"trans: \", trans.shape)\n",
    "        # From https://github.com/vgsatorras/egnn\n",
    "        # This is never activated but just in case it explosed it may save the train\n",
    "        trans = torch.clamp(trans, min=-100, max=100)\n",
    "        # print(\"trans: \", trans.shape)\n",
    "        # print(\"x.size: \", x.size(0))\n",
    "        agg = unsorted_segment_mean(trans, i, num_segments=x.size(0))\n",
    "        x = x + agg * self.c_weight # * norms[i, j], smth like that, or norms\n",
    "        return x\n",
    "\n",
    "    def minkowski_feats(self, edges, x):\n",
    "        i, j = edges\n",
    "        x_diff = x[i] - x[j]\n",
    "        norms = self.norm_fn(x_diff).unsqueeze(1)\n",
    "        dots = self.dot_fn(x[i], x[j]).unsqueeze(1)\n",
    "        norms, dots = psi(norms), psi(dots)\n",
    "        return norms, dots, x_diff\n",
    "\n",
    "    def forward(self, h, x, edges, node_attr=None):\n",
    "        i, j = edges\n",
    "        norms, dots, x_diff = self.minkowski_feats(edges, x)\n",
    "\n",
    "        if self.include_x:\n",
    "            m = self.m_model_extended(h[i], h[j], norms, dots, x[i], x[j])\n",
    "        else:\n",
    "            m = self.m_model(h[i], h[j], norms, dots) # [B*N, hidden]\n",
    "        if not self.last_layer:\n",
    "            # print(\"X: \", x)\n",
    "            x = self.x_model(x, edges, x_diff, m)\n",
    "            # print(\"phi_x(X) = \", x, '\\n---\\n')\n",
    "\n",
    "        h = self.h_model(h, edges, m, node_attr)\n",
    "        return h, x, m\n",
    "\n",
    "class LorentzNet(nn.Module):\n",
    "    r''' Implementation of LorentzNet.\n",
    "\n",
    "    Args:\n",
    "        - `n_scalar` (int): number of input scalars.\n",
    "        - `n_hidden` (int): dimension of latent space.\n",
    "        - `n_class`  (int): number of output classes.\n",
    "        - `n_layers` (int): number of LGEB layers.\n",
    "        - `c_weight` (float): weight c in the x_model.\n",
    "        - `dropout`  (float): dropout rate.\n",
    "    '''\n",
    "    def __init__(self, n_scalar, n_hidden, n_class = 2, n_layers = 6, c_weight = 1e-3, dropout = 0., A=None, include_x=False):\n",
    "        super(LorentzNet, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Linear(n_scalar, n_hidden)\n",
    "        self.LGEBs = nn.ModuleList([LGEB(self.n_hidden, self.n_hidden, self.n_hidden,\n",
    "                                    n_node_attr=n_scalar, dropout=dropout,\n",
    "                                    c_weight=c_weight, last_layer=(i==n_layers-1), A=A, include_x=include_x)\n",
    "                                    for i in range(n_layers)])\n",
    "        self.graph_dec = nn.Sequential(nn.Linear(self.n_hidden, self.n_hidden),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(dropout),\n",
    "                                       nn.Linear(self.n_hidden, n_class)) # classification\n",
    "\n",
    "    def forward(self, scalars, x, edges, node_mask, edge_mask, n_nodes):\n",
    "        h = self.embedding(scalars)\n",
    "\n",
    "        # print(\"h before (just the first particle): \\n\", h[0].cpu().detach().numpy())\n",
    "        for i in range(self.n_layers):\n",
    "            h, x, _ = self.LGEBs[i](h, x, edges, node_attr=scalars)\n",
    "        # print(\"h after (just the first particle): \\n\", h[0].cpu().detach().numpy())\n",
    "\n",
    "        h = h * node_mask\n",
    "        h = h.view(-1, n_nodes, self.n_hidden)\n",
    "        h = torch.mean(h, dim=1)\n",
    "        pred = self.graph_dec(h)\n",
    "\n",
    "        # print(\"Final preds: \\n\", pred.cpu().detach().numpy())\n",
    "        return pred.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecdc8cf",
   "metadata": {
    "id": "yKQ1ZOC2U92Y",
    "papermill": {
     "duration": 0.019636,
     "end_time": "2024-10-25T09:13:35.254004",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.234368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "LGEB(self.n_hidden, self.n_hidden, self.n_hidden,\\\n",
    "                                    n_node_attr=n_scalar, dropout=dropout,\\\n",
    "                                    c_weight=c_weight, last_layer=\\(i==n_layers-1), A=A, include_x=include_x)\n",
    "                                    \n",
    "We are using n_hidden = 4 and n_layers = 6\n",
    "\n",
    "n_input=n_hidden, n_output=n_hidden, n_hidden=n_hidden, n_node_attr=n_scalar=8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a08785",
   "metadata": {
    "id": "v_Wr8LNBXLp_",
    "papermill": {
     "duration": 0.019716,
     "end_time": "2024-10-25T09:13:35.293585",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.273869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Now that we have the official code for the classical, just for sanity checking, let's test for equivariance\n",
    "\n",
    "The cell below is just an auxiliary function to give us the boosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7aae2f0",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:35.335684Z",
     "iopub.status.busy": "2024-10-25T09:13:35.335264Z",
     "iopub.status.idle": "2024-10-25T09:13:35.344844Z",
     "shell.execute_reply": "2024-10-25T09:13:35.343820Z"
    },
    "id": "KA_EwMJIXLp_",
    "papermill": {
     "duration": 0.033451,
     "end_time": "2024-10-25T09:13:35.347083",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.313632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "# Speed of light (m/s)\n",
    "c = 299792458\n",
    "\n",
    "\"\"\"Lorentz transformations describe the transition between two inertial reference\n",
    "frames F and F', each of which is moving in some direction with respect to the\n",
    "other. This code only calculates Lorentz transformations for movement in the x\n",
    "direction with no spatial rotation (i.e., a Lorentz boost in the x direction).\n",
    "The Lorentz transformations are calculated here as linear transformations of\n",
    "four-vectors [ct, x, y, z] described by Minkowski space. Note that t (time) is\n",
    "multiplied by c (the speed of light) in the first entry of each four-vector.\n",
    "\n",
    "Thus, if X = [ct; x; y; z] and X' = [ct'; x'; y'; z'] are the four-vectors for\n",
    "two inertial reference frames and X' moves in the x direction with velocity v\n",
    "with respect to X, then the Lorentz transformation from X to X' is X' = BX,\n",
    "where\n",
    "\n",
    "    | γ  -γβ  0  0|\n",
    "B = |-γβ  γ   0  0|\n",
    "    | 0   0   1  0|\n",
    "    | 0   0   0  1|\n",
    "\n",
    "is the matrix describing the Lorentz boost between X and X',\n",
    "γ = 1 / √(1 - v²/c²) is the Lorentz factor, and β = v/c is the velocity as\n",
    "a fraction of c.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def beta(velocity: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates β = v/c, the given velocity as a fraction of c\n",
    "    >>> beta(c)\n",
    "    1.0\n",
    "    >>> beta(199792458)\n",
    "    0.666435904801848\n",
    "    \"\"\"\n",
    "    if velocity > c:\n",
    "        raise ValueError(\"Speed must not exceed light speed 299,792,458 [m/s]!\")\n",
    "    elif velocity < 1:\n",
    "        # Usually the speed should be much higher than 1 (c order of magnitude)\n",
    "        raise ValueError(\"Speed must be greater than or equal to 1!\")\n",
    "\n",
    "    return velocity / c\n",
    "\n",
    "\n",
    "def gamma(velocity: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Lorentz factor γ = 1 / √(1 - v²/c²) for a given velocity\n",
    "    >>> gamma(4)\n",
    "    1.0000000000000002\n",
    "    >>> gamma(1e5)\n",
    "    1.0000000556325075\n",
    "    >>> gamma(3e7)\n",
    "    1.005044845777813\n",
    "    >>> gamma(2.8e8)\n",
    "    2.7985595722318277\n",
    "    \"\"\"\n",
    "    return 1 / sqrt(1 - beta(velocity) ** 2)\n",
    "\n",
    "\n",
    "def transformation_matrix(velocity: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the Lorentz transformation matrix for movement in the x direction:\n",
    "\n",
    "    | γ  -γβ  0  0|\n",
    "    |-γβ  γ   0  0|\n",
    "    | 0   0   1  0|\n",
    "    | 0   0   0  1|\n",
    "\n",
    "    where γ is the Lorentz factor and β is the velocity as a fraction of c\n",
    "    >>> transformation_matrix(29979245)\n",
    "    array([[ 1.00503781, -0.10050378,  0.        ,  0.        ],\n",
    "           [-0.10050378,  1.00503781,  0.        ,  0.        ],\n",
    "           [ 0.        ,  0.        ,  1.        ,  0.        ],\n",
    "           [ 0.        ,  0.        ,  0.        ,  1.        ]])\n",
    "    \"\"\"\n",
    "    return np.array(\n",
    "        [\n",
    "            [gamma(velocity), -gamma(velocity) * beta(velocity), 0, 0],\n",
    "            [-gamma(velocity) * beta(velocity), gamma(velocity), 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1],\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9637c0f8",
   "metadata": {
    "id": "hFsrWKHLXLp_",
    "papermill": {
     "duration": 0.020349,
     "end_time": "2024-10-25T09:13:35.388232",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.367883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Now, the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25fbb67c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:35.431007Z",
     "iopub.status.busy": "2024-10-25T09:13:35.430167Z",
     "iopub.status.idle": "2024-10-25T09:13:35.443081Z",
     "shell.execute_reply": "2024-10-25T09:13:35.442004Z"
    },
    "id": "cp9yZmnOXLqA",
    "outputId": "9b6bec5f-a280-4fe6-ed2a-39c8d24b05c7",
    "papermill": {
     "duration": 0.036702,
     "end_time": "2024-10-25T09:13:35.445380",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.408678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size of phi_e:  4\n"
     ]
    }
   ],
   "source": [
    "# n_scalar = 8 in original !\n",
    "model = LorentzNet(n_scalar = 1, n_hidden = 4, n_class = 2,\\\n",
    "                       dropout = 0.2, n_layers = 1,\\\n",
    "                       c_weight = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f90c59",
   "metadata": {
    "id": "hE-OtUjVXLqA",
    "papermill": {
     "duration": 0.019891,
     "end_time": "2024-10-25T09:13:35.485682",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.465791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Let's start with a default prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52e14966",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:35.527804Z",
     "iopub.status.busy": "2024-10-25T09:13:35.527371Z",
     "iopub.status.idle": "2024-10-25T09:13:35.581481Z",
     "shell.execute_reply": "2024-10-25T09:13:35.580175Z"
    },
    "id": "zzcmDxZxXLqA",
    "papermill": {
     "duration": 0.078423,
     "end_time": "2024-10-25T09:13:35.584262",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.505839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model(scalars=nodes, x=atom_positions, edges=edges, node_mask=atom_mask,\n",
    "                     edge_mask=edge_mask, n_nodes=n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e906b68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:35.628780Z",
     "iopub.status.busy": "2024-10-25T09:13:35.627798Z",
     "iopub.status.idle": "2024-10-25T09:13:35.638344Z",
     "shell.execute_reply": "2024-10-25T09:13:35.637286Z"
    },
    "id": "R4k_rlP6XLqF",
    "papermill": {
     "duration": 0.034684,
     "end_time": "2024-10-25T09:13:35.640581",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.605897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model(scalars=nodes, x=atom_positions, edges=edges, node_mask=atom_mask,\n",
    "                     edge_mask=edge_mask, n_nodes=n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7012d763",
   "metadata": {
    "id": "1WHsdTBxXLqF",
    "papermill": {
     "duration": 0.020736,
     "end_time": "2024-10-25T09:13:35.681905",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.661169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ... taking any random nonsense transformation in the four-momentum vectors\n",
    "i.e.: multiplying by 0.1. Does the hidden rep stay the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04cde867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:35.724594Z",
     "iopub.status.busy": "2024-10-25T09:13:35.724213Z",
     "iopub.status.idle": "2024-10-25T09:13:35.731724Z",
     "shell.execute_reply": "2024-10-25T09:13:35.730720Z"
    },
    "id": "8Hxk_CYJXLqG",
    "papermill": {
     "duration": 0.031475,
     "end_time": "2024-10-25T09:13:35.734072",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.702597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model(scalars=nodes, x= 0.1 * atom_positions, edges=edges, node_mask=atom_mask,\n",
    "                     edge_mask=edge_mask, n_nodes=n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f6a33d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:35.777316Z",
     "iopub.status.busy": "2024-10-25T09:13:35.776206Z",
     "iopub.status.idle": "2024-10-25T09:13:35.783419Z",
     "shell.execute_reply": "2024-10-25T09:13:35.782329Z"
    },
    "id": "1EiVpL33XLqG",
    "papermill": {
     "duration": 0.031541,
     "end_time": "2024-10-25T09:13:35.785995",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.754454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model(scalars=nodes, x= 0.1 * atom_positions, edges=edges, node_mask=atom_mask,\n",
    "                     edge_mask=edge_mask, n_nodes=n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c036d",
   "metadata": {
    "id": "70ulhirrXLqH",
    "papermill": {
     "duration": 0.019826,
     "end_time": "2024-10-25T09:13:35.826288",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.806462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Even though the final logits in this case wasn't different, if we look the last output of h (which contains both scalar and 4-momenta information), it changed! Now, what about Lorentz transformations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad59c2ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:35.868845Z",
     "iopub.status.busy": "2024-10-25T09:13:35.867883Z",
     "iopub.status.idle": "2024-10-25T09:13:35.879247Z",
     "shell.execute_reply": "2024-10-25T09:13:35.878161Z"
    },
    "id": "2IVU9kGJXLqH",
    "papermill": {
     "duration": 0.03548,
     "end_time": "2024-10-25T09:13:35.881827",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.846347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model(scalars=nodes, x= (torch.tensor(transformation_matrix(220000000)) @ atom_positions.to(dtype=torch.float64).T).to(dtype=torch.float32).T, edges=edges, node_mask=atom_mask,\n",
    "                     edge_mask=edge_mask, n_nodes=n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d260a906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:35.925325Z",
     "iopub.status.busy": "2024-10-25T09:13:35.924194Z",
     "iopub.status.idle": "2024-10-25T09:13:35.932650Z",
     "shell.execute_reply": "2024-10-25T09:13:35.931660Z"
    },
    "id": "U1AUOcTDXLqH",
    "papermill": {
     "duration": 0.032471,
     "end_time": "2024-10-25T09:13:35.934900",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.902429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model(scalars=nodes, x= (torch.tensor(transformation_matrix(220000000)) @ atom_positions.to(dtype=torch.float64).T).to(dtype=torch.float32).T, edges=edges, node_mask=atom_mask,\n",
    "                     edge_mask=edge_mask, n_nodes=n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1fe30",
   "metadata": {
    "id": "dRYlUAEVXLqI",
    "papermill": {
     "duration": 0.019875,
     "end_time": "2024-10-25T09:13:35.975277",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.955402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Equivariance works. Finally, let's train on some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91d051a9",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:36.018675Z",
     "iopub.status.busy": "2024-10-25T09:13:36.017968Z",
     "iopub.status.idle": "2024-10-25T09:13:36.156351Z",
     "shell.execute_reply": "2024-10-25T09:13:36.155050Z"
    },
    "id": "KRBzC37VorM9",
    "papermill": {
     "duration": 0.163449,
     "end_time": "2024-10-25T09:13:36.158962",
     "exception": false,
     "start_time": "2024-10-25T09:13:35.995513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import torch\n",
    "import os, json, random, string\n",
    "import torch.distributed as dist\n",
    "\n",
    "def makedir(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "def args_init(args):\n",
    "    r''' Initialize seed and exp_name.\n",
    "    '''\n",
    "    if args.seed is None: # use random seed if not specified\n",
    "        args.seed = np.random.randint(100)\n",
    "    if args.exp_name == '': # use random strings if not specified\n",
    "        args.exp_name = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))\n",
    "    if (args.local_rank == 0): # master\n",
    "        print(args)\n",
    "        makedir(f\"{args.logdir}/{args.exp_name}\")\n",
    "        with open(f\"{args.logdir}/{args.exp_name}/args.json\", 'w') as f:\n",
    "            json.dump(args.__dict__, f, indent=4)\n",
    "\n",
    "def sum_reduce(num, device):\n",
    "    r''' Sum the tensor across the devices.\n",
    "    '''\n",
    "    if not torch.is_tensor(num):\n",
    "        rt = torch.tensor(num).to(device)\n",
    "    else:\n",
    "        rt = num.clone()\n",
    "    dist.all_reduce(rt, op=dist.ReduceOp.SUM)\n",
    "    return rt\n",
    "\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class GradualWarmupScheduler(_LRScheduler):\n",
    "    \"\"\" Gradually warm-up(increasing) learning rate in optimizer.\n",
    "    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        multiplier: target learning rate = base lr * multiplier if multiplier > 1.0. if multiplier = 1.0, lr starts from 0 and ends up with the base_lr.\n",
    "        warmup_epoch: target learning rate is reached at warmup_epoch, gradually\n",
    "        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n",
    "    Reference:\n",
    "        https://github.com/ildoonet/pytorch-gradual-warmup-lr\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, multiplier, warmup_epoch, after_scheduler=None):\n",
    "        self.multiplier = multiplier\n",
    "        if self.multiplier < 1.:\n",
    "            raise ValueError('multiplier should be greater thant or equal to 1.')\n",
    "        self.warmup_epoch = warmup_epoch\n",
    "        self.after_scheduler = after_scheduler\n",
    "        self.finished = False\n",
    "        super(GradualWarmupScheduler, self).__init__(optimizer)\n",
    "\n",
    "    @property\n",
    "    def _warmup_lr(self):\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch + 1) / self.warmup_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * (self.last_epoch + 1) / self.warmup_epoch + 1.) for base_lr in self.base_lrs]\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch >= self.warmup_epoch - 1:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_last_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "\n",
    "        return self._warmup_lr\n",
    "\n",
    "    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n",
    "        self.last_epoch = self.last_epoch + 1 if epoch==None else epoch\n",
    "        if self.last_epoch >= self.warmup_epoch - 1:\n",
    "            if not self.finished:\n",
    "                warmup_lr = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n",
    "                    param_group['lr'] = lr\n",
    "                self.finished = True\n",
    "                return\n",
    "            if epoch is None:\n",
    "                self.after_scheduler.step(metrics, None)\n",
    "            else:\n",
    "                self.after_scheduler.step(metrics, epoch - self.warmup_epoch)\n",
    "            return\n",
    "\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self._warmup_lr):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def step(self, epoch=None, metrics=None):\n",
    "        if type(self.after_scheduler) != ReduceLROnPlateau:\n",
    "            if self.finished and self.after_scheduler:\n",
    "                if epoch is None:\n",
    "                    self.after_scheduler.step(None)\n",
    "                else:\n",
    "                    self.after_scheduler.step(epoch - self.warmup_epoch)\n",
    "                self.last_epoch = self.after_scheduler.last_epoch + self.warmup_epoch + 1\n",
    "                self._last_lr = self.after_scheduler.get_last_lr()\n",
    "            else:\n",
    "                return super(GradualWarmupScheduler, self).step(epoch)\n",
    "        else:\n",
    "            self.step_ReduceLROnPlateau(metrics, epoch)\n",
    "\n",
    "        self._last_lr = [group['lr'] for group in self.optimizer.param_groups]\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"Returns the state of the scheduler as a :class:`dict`.\n",
    "\n",
    "        It contains an entry for every variable in self.__dict__ which\n",
    "        is not the optimizer.\n",
    "        \"\"\"\n",
    "        result = {key: value for key, value in self.__dict__.items() if key != 'optimizer' or key != \"after_scheduler\"}\n",
    "        if self.after_scheduler:\n",
    "            result.update({\"after_scheduler\": self.after_scheduler.state_dict()})\n",
    "        return result\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        after_scheduler_state = state_dict.pop(\"after_scheduler\", None)\n",
    "        self.__dict__.update(state_dict)\n",
    "        if after_scheduler_state:\n",
    "            self.after_scheduler.load_state_dict(after_scheduler_state)\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "def buildROC(labels, score, targetEff=[0.3,0.5]):\n",
    "    r''' ROC curve is a plot of the true positive rate (Sensitivity) in the function of the false positive rate\n",
    "    (100-Specificity) for different cut-off points of a parameter. Each point on the ROC curve represents a\n",
    "    sensitivity/specificity pair corresponding to a particular decision threshold. The Area Under the ROC\n",
    "    curve (AUC) is a measure of how well a parameter can distinguish between two diagnostic groups.\n",
    "    '''\n",
    "    if not isinstance(targetEff, list):\n",
    "        targetEff = [targetEff]\n",
    "    fpr, tpr, threshold = roc_curve(labels, score)\n",
    "    idx = [np.argmin(np.abs(tpr - Eff)) for Eff in targetEff]\n",
    "    eB, eS = fpr[idx], tpr[idx]\n",
    "    return fpr, tpr, threshold, eB, eS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "740e5a78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:36.204466Z",
     "iopub.status.busy": "2024-10-25T09:13:36.204058Z",
     "iopub.status.idle": "2024-10-25T09:13:57.505966Z",
     "shell.execute_reply": "2024-10-25T09:13:57.504018Z"
    },
    "id": "8azxxVjtXLqI",
    "outputId": "3deb62b1-8ab6-43e5-d765-f7dc0e49a783",
    "papermill": {
     "duration": 21.328155,
     "end_time": "2024-10-25T09:13:57.508416",
     "exception": false,
     "start_time": "2024-10-25T09:13:36.180261",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size of phi_e:  4\n",
      "Model Size: 199\n",
      " train samples: 800\n",
      " val samples: 100\n",
      " test samples: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 109.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 1/45 \t Batch 49/50 \t Loss 0.6834 \t Running Acc 0.494 \t Total Acc 0.494 \t Avg Batch Time 0.0092\n",
      "Time: train: 0.46 \t Train loss 0.6834 \t Train acc: 0.4938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 249.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6775 \t Running Acc 1.857 \t Total Acc 0.520 \t Avg Batch Time 0.0012\n",
      "New best validation model, saving...\n",
      "Epoch 0/45 finished.\n",
      "Train time: 0.46 \t Val time 0.03\n",
      "Train loss 0.6834 \t Train acc: 0.4938\n",
      "Val loss: 0.6758 \t Val acc: 0.5200\n",
      "Best val acc: 0.5200 at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 116.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 2/45 \t Batch 49/50 \t Loss 0.6821 \t Running Acc 0.517 \t Total Acc 0.517 \t Avg Batch Time 0.0086\n",
      "Time: train: 0.43 \t Train loss 0.6821 \t Train acc: 0.5175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 267.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6729 \t Running Acc 1.857 \t Total Acc 0.520 \t Avg Batch Time 0.0011\n",
      "Epoch 1/45 finished.\n",
      "Train time: 0.43 \t Val time 0.03\n",
      "Train loss 0.6821 \t Train acc: 0.5175\n",
      "Val loss: 0.6706 \t Val acc: 0.5200\n",
      "Best val acc: 0.5200 at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 122.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 3/45 \t Batch 49/50 \t Loss 0.6765 \t Running Acc 0.519 \t Total Acc 0.519 \t Avg Batch Time 0.0082\n",
      "Time: train: 0.41 \t Train loss 0.6765 \t Train acc: 0.5188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 257.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6676 \t Running Acc 1.893 \t Total Acc 0.530 \t Avg Batch Time 0.0012\n",
      "New best validation model, saving...\n",
      "Epoch 2/45 finished.\n",
      "Train time: 0.41 \t Val time 0.03\n",
      "Train loss 0.6765 \t Train acc: 0.5188\n",
      "Val loss: 0.6648 \t Val acc: 0.5300\n",
      "Best val acc: 0.5300 at epoch 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 116.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 4/45 \t Batch 49/50 \t Loss 0.6702 \t Running Acc 0.554 \t Total Acc 0.554 \t Avg Batch Time 0.0086\n",
      "Time: train: 0.43 \t Train loss 0.6702 \t Train acc: 0.5537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 264.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6606 \t Running Acc 2.000 \t Total Acc 0.560 \t Avg Batch Time 0.0011\n",
      "New best validation model, saving...\n",
      "Epoch 3/45 finished.\n",
      "Train time: 0.43 \t Val time 0.03\n",
      "Train loss 0.6702 \t Train acc: 0.5537\n",
      "Val loss: 0.6569 \t Val acc: 0.5600\n",
      "Best val acc: 0.5600 at epoch 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 120.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 5/45 \t Batch 49/50 \t Loss 0.6627 \t Running Acc 0.569 \t Total Acc 0.569 \t Avg Batch Time 0.0083\n",
      "Time: train: 0.42 \t Train loss 0.6627 \t Train acc: 0.5687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 245.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6513 \t Running Acc 2.321 \t Total Acc 0.650 \t Avg Batch Time 0.0012\n",
      "New best validation model, saving...\n",
      "Epoch 4/45 finished.\n",
      "Train time: 0.42 \t Val time 0.03\n",
      "Train loss 0.6627 \t Train acc: 0.5687\n",
      "Val loss: 0.6466 \t Val acc: 0.6500\n",
      "Best val acc: 0.6500 at epoch 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 124.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 6/45 \t Batch 49/50 \t Loss 0.6519 \t Running Acc 0.618 \t Total Acc 0.618 \t Avg Batch Time 0.0081\n",
      "Time: train: 0.40 \t Train loss 0.6519 \t Train acc: 0.6175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 234.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6433 \t Running Acc 2.464 \t Total Acc 0.690 \t Avg Batch Time 0.0013\n",
      "New best validation model, saving...\n",
      "Epoch 5/45 finished.\n",
      "Train time: 0.40 \t Val time 0.03\n",
      "Train loss 0.6519 \t Train acc: 0.6175\n",
      "Val loss: 0.6376 \t Val acc: 0.6900\n",
      "Best val acc: 0.6900 at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 123.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 7/45 \t Batch 49/50 \t Loss 0.6463 \t Running Acc 0.624 \t Total Acc 0.624 \t Avg Batch Time 0.0081\n",
      "Time: train: 0.41 \t Train loss 0.6463 \t Train acc: 0.6238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 261.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6384 \t Running Acc 2.643 \t Total Acc 0.740 \t Avg Batch Time 0.0011\n",
      "New best validation model, saving...\n",
      "Epoch 6/45 finished.\n",
      "Train time: 0.41 \t Val time 0.03\n",
      "Train loss 0.6463 \t Train acc: 0.6238\n",
      "Val loss: 0.6321 \t Val acc: 0.7400\n",
      "Best val acc: 0.7400 at epoch 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 124.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 8/45 \t Batch 49/50 \t Loss 0.6418 \t Running Acc 0.642 \t Total Acc 0.642 \t Avg Batch Time 0.0081\n",
      "Time: train: 0.40 \t Train loss 0.6418 \t Train acc: 0.6425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 258.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6372 \t Running Acc 2.643 \t Total Acc 0.740 \t Avg Batch Time 0.0012\n",
      "Epoch 7/45 finished.\n",
      "Train time: 0.40 \t Val time 0.03\n",
      "Train loss 0.6418 \t Train acc: 0.6425\n",
      "Val loss: 0.6307 \t Val acc: 0.7400\n",
      "Best val acc: 0.7400 at epoch 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 115.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 9/45 \t Batch 49/50 \t Loss 0.6442 \t Running Acc 0.677 \t Total Acc 0.677 \t Avg Batch Time 0.0087\n",
      "Time: train: 0.44 \t Train loss 0.6442 \t Train acc: 0.6775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 271.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6240 \t Running Acc 2.821 \t Total Acc 0.790 \t Avg Batch Time 0.0012\n",
      "New best validation model, saving...\n",
      "Epoch 8/45 finished.\n",
      "Train time: 0.44 \t Val time 0.03\n",
      "Train loss 0.6442 \t Train acc: 0.6775\n",
      "Val loss: 0.6153 \t Val acc: 0.7900\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 119.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 10/45 \t Batch 49/50 \t Loss 0.6215 \t Running Acc 0.706 \t Total Acc 0.706 \t Avg Batch Time 0.0084\n",
      "Time: train: 0.42 \t Train loss 0.6215 \t Train acc: 0.7063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 269.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6079 \t Running Acc 2.750 \t Total Acc 0.770 \t Avg Batch Time 0.0011\n",
      "Epoch 9/45 finished.\n",
      "Train time: 0.42 \t Val time 0.03\n",
      "Train loss 0.6215 \t Train acc: 0.7063\n",
      "Val loss: 0.5964 \t Val acc: 0.7700\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 119.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 11/45 \t Batch 49/50 \t Loss 0.6074 \t Running Acc 0.723 \t Total Acc 0.723 \t Avg Batch Time 0.0084\n",
      "Time: train: 0.42 \t Train loss 0.6074 \t Train acc: 0.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 261.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5984 \t Running Acc 2.786 \t Total Acc 0.780 \t Avg Batch Time 0.0012\n",
      "Epoch 10/45 finished.\n",
      "Train time: 0.42 \t Val time 0.03\n",
      "Train loss 0.6074 \t Train acc: 0.7225\n",
      "Val loss: 0.5855 \t Val acc: 0.7800\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 121.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 12/45 \t Batch 49/50 \t Loss 0.6014 \t Running Acc 0.738 \t Total Acc 0.738 \t Avg Batch Time 0.0083\n",
      "Time: train: 0.41 \t Train loss 0.6014 \t Train acc: 0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 268.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5912 \t Running Acc 2.786 \t Total Acc 0.780 \t Avg Batch Time 0.0011\n",
      "Epoch 11/45 finished.\n",
      "Train time: 0.41 \t Val time 0.03\n",
      "Train loss 0.6014 \t Train acc: 0.7375\n",
      "Val loss: 0.5770 \t Val acc: 0.7800\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 124.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 13/45 \t Batch 49/50 \t Loss 0.5975 \t Running Acc 0.714 \t Total Acc 0.714 \t Avg Batch Time 0.0081\n",
      "Time: train: 0.40 \t Train loss 0.5975 \t Train acc: 0.7137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 237.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5896 \t Running Acc 2.750 \t Total Acc 0.770 \t Avg Batch Time 0.0013\n",
      "Epoch 12/45 finished.\n",
      "Train time: 0.40 \t Val time 0.03\n",
      "Train loss 0.5975 \t Train acc: 0.7137\n",
      "Val loss: 0.5749 \t Val acc: 0.7700\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 120.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 14/45 \t Batch 49/50 \t Loss 0.5916 \t Running Acc 0.725 \t Total Acc 0.725 \t Avg Batch Time 0.0084\n",
      "Time: train: 0.42 \t Train loss 0.5916 \t Train acc: 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 249.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5871 \t Running Acc 2.750 \t Total Acc 0.770 \t Avg Batch Time 0.0012\n",
      "Epoch 13/45 finished.\n",
      "Train time: 0.42 \t Val time 0.03\n",
      "Train loss 0.5916 \t Train acc: 0.7250\n",
      "Val loss: 0.5717 \t Val acc: 0.7700\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 121.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 15/45 \t Batch 49/50 \t Loss 0.5873 \t Running Acc 0.741 \t Total Acc 0.741 \t Avg Batch Time 0.0083\n",
      "Time: train: 0.41 \t Train loss 0.5873 \t Train acc: 0.7412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 249.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5861 \t Running Acc 2.750 \t Total Acc 0.770 \t Avg Batch Time 0.0012\n",
      "Epoch 14/45 finished.\n",
      "Train time: 0.41 \t Val time 0.03\n",
      "Train loss 0.5873 \t Train acc: 0.7412\n",
      "Val loss: 0.5704 \t Val acc: 0.7700\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 125.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 16/45 \t Batch 49/50 \t Loss 0.5889 \t Running Acc 0.728 \t Total Acc 0.728 \t Avg Batch Time 0.0080\n",
      "Time: train: 0.40 \t Train loss 0.5889 \t Train acc: 0.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 247.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5859 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 0.0012\n",
      "Epoch 15/45 finished.\n",
      "Train time: 0.40 \t Val time 0.03\n",
      "Train loss 0.5889 \t Train acc: 0.7275\n",
      "Val loss: 0.5701 \t Val acc: 0.7600\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 127.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 17/45 \t Batch 49/50 \t Loss 0.5829 \t Running Acc 0.734 \t Total Acc 0.734 \t Avg Batch Time 0.0079\n",
      "Time: train: 0.40 \t Train loss 0.5829 \t Train acc: 0.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 269.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5786 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 0.0011\n",
      "Epoch 16/45 finished.\n",
      "Train time: 0.40 \t Val time 0.03\n",
      "Train loss 0.5829 \t Train acc: 0.7338\n",
      "Val loss: 0.5611 \t Val acc: 0.7600\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 124.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 18/45 \t Batch 49/50 \t Loss 0.5815 \t Running Acc 0.744 \t Total Acc 0.744 \t Avg Batch Time 0.0081\n",
      "Time: train: 0.40 \t Train loss 0.5815 \t Train acc: 0.7438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 253.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5722 \t Running Acc 2.750 \t Total Acc 0.770 \t Avg Batch Time 0.0012\n",
      "Epoch 17/45 finished.\n",
      "Train time: 0.40 \t Val time 0.03\n",
      "Train loss 0.5815 \t Train acc: 0.7438\n",
      "Val loss: 0.5528 \t Val acc: 0.7700\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 119.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 19/45 \t Batch 49/50 \t Loss 0.5662 \t Running Acc 0.743 \t Total Acc 0.743 \t Avg Batch Time 0.0084\n",
      "Time: train: 0.42 \t Train loss 0.5662 \t Train acc: 0.7425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 231.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5667 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 0.0013\n",
      "Epoch 18/45 finished.\n",
      "Train time: 0.42 \t Val time 0.03\n",
      "Train loss 0.5662 \t Train acc: 0.7425\n",
      "Val loss: 0.5463 \t Val acc: 0.7600\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 116.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 20/45 \t Batch 49/50 \t Loss 0.5631 \t Running Acc 0.750 \t Total Acc 0.750 \t Avg Batch Time 0.0087\n",
      "Time: train: 0.43 \t Train loss 0.5631 \t Train acc: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 261.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5630 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 0.0012\n",
      "Epoch 19/45 finished.\n",
      "Train time: 0.43 \t Val time 0.03\n",
      "Train loss 0.5631 \t Train acc: 0.7500\n",
      "Val loss: 0.5410 \t Val acc: 0.7600\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 128.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 21/45 \t Batch 49/50 \t Loss 0.5633 \t Running Acc 0.748 \t Total Acc 0.748 \t Avg Batch Time 0.0079\n",
      "Time: train: 0.39 \t Train loss 0.5633 \t Train acc: 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 242.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5608 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 0.0012\n",
      "Epoch 20/45 finished.\n",
      "Train time: 0.39 \t Val time 0.03\n",
      "Train loss 0.5633 \t Train acc: 0.7475\n",
      "Val loss: 0.5377 \t Val acc: 0.7600\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 126.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 22/45 \t Batch 49/50 \t Loss 0.5553 \t Running Acc 0.749 \t Total Acc 0.749 \t Avg Batch Time 0.0080\n",
      "Time: train: 0.40 \t Train loss 0.5553 \t Train acc: 0.7488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 260.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5573 \t Running Acc 2.750 \t Total Acc 0.770 \t Avg Batch Time 0.0012\n",
      "Epoch 21/45 finished.\n",
      "Train time: 0.40 \t Val time 0.03\n",
      "Train loss 0.5553 \t Train acc: 0.7488\n",
      "Val loss: 0.5323 \t Val acc: 0.7700\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 120.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 23/45 \t Batch 49/50 \t Loss 0.5550 \t Running Acc 0.741 \t Total Acc 0.741 \t Avg Batch Time 0.0083\n",
      "Time: train: 0.42 \t Train loss 0.5550 \t Train acc: 0.7412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 253.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5583 \t Running Acc 2.679 \t Total Acc 0.750 \t Avg Batch Time 0.0012\n",
      "Epoch 22/45 finished.\n",
      "Train time: 0.42 \t Val time 0.03\n",
      "Train loss 0.5550 \t Train acc: 0.7412\n",
      "Val loss: 0.5342 \t Val acc: 0.7500\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 122.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 24/45 \t Batch 49/50 \t Loss 0.5568 \t Running Acc 0.736 \t Total Acc 0.736 \t Avg Batch Time 0.0082\n",
      "Time: train: 0.41 \t Train loss 0.5568 \t Train acc: 0.7362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 265.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5568 \t Running Acc 2.643 \t Total Acc 0.740 \t Avg Batch Time 0.0011\n",
      "Epoch 23/45 finished.\n",
      "Train time: 0.41 \t Val time 0.03\n",
      "Train loss 0.5568 \t Train acc: 0.7362\n",
      "Val loss: 0.5313 \t Val acc: 0.7400\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 123.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 25/45 \t Batch 49/50 \t Loss 0.5513 \t Running Acc 0.743 \t Total Acc 0.743 \t Avg Batch Time 0.0081\n",
      "Time: train: 0.41 \t Train loss 0.5513 \t Train acc: 0.7425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 256.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5557 \t Running Acc 2.643 \t Total Acc 0.740 \t Avg Batch Time 0.0012\n",
      "Epoch 24/45 finished.\n",
      "Train time: 0.41 \t Val time 0.03\n",
      "Train loss 0.5513 \t Train acc: 0.7425\n",
      "Val loss: 0.5290 \t Val acc: 0.7400\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 119.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 26/45 \t Batch 49/50 \t Loss 0.5470 \t Running Acc 0.755 \t Total Acc 0.755 \t Avg Batch Time 0.0084\n",
      "Time: train: 0.42 \t Train loss 0.5470 \t Train acc: 0.7550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 257.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5538 \t Running Acc 2.643 \t Total Acc 0.740 \t Avg Batch Time 0.0012\n",
      "Epoch 25/45 finished.\n",
      "Train time: 0.42 \t Val time 0.03\n",
      "Train loss 0.5470 \t Train acc: 0.7550\n",
      "Val loss: 0.5264 \t Val acc: 0.7400\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 117.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 27/45 \t Batch 49/50 \t Loss 0.5487 \t Running Acc 0.750 \t Total Acc 0.750 \t Avg Batch Time 0.0086\n",
      "Time: train: 0.43 \t Train loss 0.5487 \t Train acc: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 248.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.643 \t Total Acc 0.740 \t Avg Batch Time 0.0012\n",
      "Epoch 26/45 finished.\n",
      "Train time: 0.43 \t Val time 0.03\n",
      "Train loss 0.5487 \t Train acc: 0.7500\n",
      "Val loss: 0.5255 \t Val acc: 0.7400\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 121.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 28/45 \t Batch 49/50 \t Loss 0.5458 \t Running Acc 0.762 \t Total Acc 0.762 \t Avg Batch Time 0.0083\n",
      "Time: train: 0.41 \t Train loss 0.5458 \t Train acc: 0.7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 207.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5536 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0014\n",
      "Epoch 27/45 finished.\n",
      "Train time: 0.41 \t Val time 0.04\n",
      "Train loss 0.5458 \t Train acc: 0.7625\n",
      "Val loss: 0.5258 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 122.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 29/45 \t Batch 49/50 \t Loss 0.5487 \t Running Acc 0.756 \t Total Acc 0.756 \t Avg Batch Time 0.0082\n",
      "Time: train: 0.41 \t Train loss 0.5487 \t Train acc: 0.7562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 272.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5533 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0011\n",
      "Epoch 28/45 finished.\n",
      "Train time: 0.41 \t Val time 0.03\n",
      "Train loss 0.5487 \t Train acc: 0.7562\n",
      "Val loss: 0.5253 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 127.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 30/45 \t Batch 49/50 \t Loss 0.5494 \t Running Acc 0.746 \t Total Acc 0.746 \t Avg Batch Time 0.0079\n",
      "Time: train: 0.39 \t Train loss 0.5494 \t Train acc: 0.7462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 276.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5533 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0011\n",
      "Epoch 29/45 finished.\n",
      "Train time: 0.39 \t Val time 0.03\n",
      "Train loss 0.5494 \t Train acc: 0.7462\n",
      "Val loss: 0.5253 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 127.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 31/45 \t Batch 49/50 \t Loss 0.5427 \t Running Acc 0.743 \t Total Acc 0.743 \t Avg Batch Time 0.0079\n",
      "Time: train: 0.39 \t Train loss 0.5427 \t Train acc: 0.7425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 267.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5531 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0011\n",
      "Epoch 30/45 finished.\n",
      "Train time: 0.39 \t Val time 0.03\n",
      "Train loss 0.5427 \t Train acc: 0.7425\n",
      "Val loss: 0.5250 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 113.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 32/45 \t Batch 49/50 \t Loss 0.5489 \t Running Acc 0.746 \t Total Acc 0.746 \t Avg Batch Time 0.0088\n",
      "Time: train: 0.44 \t Train loss 0.5489 \t Train acc: 0.7462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 246.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0012\n",
      "Epoch 31/45 finished.\n",
      "Train time: 0.44 \t Val time 0.03\n",
      "Train loss 0.5489 \t Train acc: 0.7462\n",
      "Val loss: 0.5250 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 111.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 33/45 \t Batch 49/50 \t Loss 0.5566 \t Running Acc 0.721 \t Total Acc 0.721 \t Avg Batch Time 0.0090\n",
      "Time: train: 0.45 \t Train loss 0.5566 \t Train acc: 0.7212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 258.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0012\n",
      "Epoch 32/45 finished.\n",
      "Train time: 0.45 \t Val time 0.03\n",
      "Train loss 0.5566 \t Train acc: 0.7212\n",
      "Val loss: 0.5251 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 119.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 34/45 \t Batch 49/50 \t Loss 0.5476 \t Running Acc 0.748 \t Total Acc 0.748 \t Avg Batch Time 0.0084\n",
      "Time: train: 0.42 \t Train loss 0.5476 \t Train acc: 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 264.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0011\n",
      "Epoch 33/45 finished.\n",
      "Train time: 0.42 \t Val time 0.03\n",
      "Train loss 0.5476 \t Train acc: 0.7475\n",
      "Val loss: 0.5251 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 127.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 35/45 \t Batch 49/50 \t Loss 0.5395 \t Running Acc 0.760 \t Total Acc 0.760 \t Avg Batch Time 0.0079\n",
      "Time: train: 0.39 \t Train loss 0.5395 \t Train acc: 0.7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 253.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0012\n",
      "Epoch 34/45 finished.\n",
      "Train time: 0.39 \t Val time 0.03\n",
      "Train loss 0.5395 \t Train acc: 0.7600\n",
      "Val loss: 0.5250 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 125.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 36/45 \t Batch 49/50 \t Loss 0.5549 \t Running Acc 0.738 \t Total Acc 0.738 \t Avg Batch Time 0.0080\n",
      "Time: train: 0.40 \t Train loss 0.5549 \t Train acc: 0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 254.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0012\n",
      "Epoch 35/45 finished.\n",
      "Train time: 0.40 \t Val time 0.03\n",
      "Train loss 0.5549 \t Train acc: 0.7375\n",
      "Val loss: 0.5251 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 110.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 37/45 \t Batch 49/50 \t Loss 0.5486 \t Running Acc 0.738 \t Total Acc 0.738 \t Avg Batch Time 0.0091\n",
      "Time: train: 0.45 \t Train loss 0.5486 \t Train acc: 0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 259.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0012\n",
      "Epoch 36/45 finished.\n",
      "Train time: 0.45 \t Val time 0.03\n",
      "Train loss 0.5486 \t Train acc: 0.7375\n",
      "Val loss: 0.5251 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 121.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 38/45 \t Batch 49/50 \t Loss 0.5428 \t Running Acc 0.757 \t Total Acc 0.757 \t Avg Batch Time 0.0083\n",
      "Time: train: 0.41 \t Train loss 0.5428 \t Train acc: 0.7575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 260.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0012\n",
      "Epoch 37/45 finished.\n",
      "Train time: 0.41 \t Val time 0.03\n",
      "Train loss 0.5428 \t Train acc: 0.7575\n",
      "Val loss: 0.5251 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 116.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 39/45 \t Batch 49/50 \t Loss 0.5396 \t Running Acc 0.744 \t Total Acc 0.744 \t Avg Batch Time 0.0086\n",
      "Time: train: 0.43 \t Train loss 0.5396 \t Train acc: 0.7438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 261.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0011\n",
      "Epoch 38/45 finished.\n",
      "Train time: 0.43 \t Val time 0.03\n",
      "Train loss 0.5396 \t Train acc: 0.7438\n",
      "Val loss: 0.5251 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 121.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 40/45 \t Batch 49/50 \t Loss 0.5523 \t Running Acc 0.761 \t Total Acc 0.761 \t Avg Batch Time 0.0083\n",
      "Time: train: 0.42 \t Train loss 0.5523 \t Train acc: 0.7612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 256.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0012\n",
      "Epoch 39/45 finished.\n",
      "Train time: 0.42 \t Val time 0.03\n",
      "Train loss 0.5523 \t Train acc: 0.7612\n",
      "Val loss: 0.5251 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 113.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 41/45 \t Batch 49/50 \t Loss 0.5421 \t Running Acc 0.756 \t Total Acc 0.756 \t Avg Batch Time 0.0089\n",
      "Time: train: 0.44 \t Train loss 0.5421 \t Train acc: 0.7562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 231.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0013\n",
      "Epoch 40/45 finished.\n",
      "Train time: 0.44 \t Val time 0.03\n",
      "Train loss 0.5421 \t Train acc: 0.7562\n",
      "Val loss: 0.5251 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 109.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 42/45 \t Batch 49/50 \t Loss 0.5452 \t Running Acc 0.750 \t Total Acc 0.750 \t Avg Batch Time 0.0092\n",
      "Time: train: 0.46 \t Train loss 0.5452 \t Train acc: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 237.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0013\n",
      "Epoch 41/45 finished.\n",
      "Train time: 0.46 \t Val time 0.03\n",
      "Train loss 0.5452 \t Train acc: 0.7500\n",
      "Val loss: 0.5251 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 117.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 43/45 \t Batch 49/50 \t Loss 0.5487 \t Running Acc 0.750 \t Total Acc 0.750 \t Avg Batch Time 0.0086\n",
      "Time: train: 0.43 \t Train loss 0.5487 \t Train acc: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 235.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0013\n",
      "Epoch 42/45 finished.\n",
      "Train time: 0.43 \t Val time 0.03\n",
      "Train loss 0.5487 \t Train acc: 0.7500\n",
      "Val loss: 0.5251 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 122.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 44/45 \t Batch 49/50 \t Loss 0.5442 \t Running Acc 0.751 \t Total Acc 0.751 \t Avg Batch Time 0.0082\n",
      "Time: train: 0.41 \t Train loss 0.5442 \t Train acc: 0.7512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 258.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0012\n",
      "Epoch 43/45 finished.\n",
      "Train time: 0.41 \t Val time 0.03\n",
      "Train loss 0.5442 \t Train acc: 0.7512\n",
      "Val loss: 0.5251 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 116.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 45/45 \t Batch 49/50 \t Loss 0.5403 \t Running Acc 0.757 \t Total Acc 0.757 \t Avg Batch Time 0.0086\n",
      "Time: train: 0.43 \t Train loss 0.5403 \t Train acc: 0.7575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 247.42it/s]\n",
      "/tmp/ipykernel_17/813438993.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model = torch.load(os.path.join(model_path, \"best-val-model.pt\"), map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5532 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 0.0012\n",
      "Epoch 44/45 finished.\n",
      "Train time: 0.43 \t Val time 0.03\n",
      "Train loss 0.5403 \t Train acc: 0.7575\n",
      "Val loss: 0.5251 \t Val acc: 0.7300\n",
      "Best val acc: 0.7900 at epoch 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 244.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> test \t Loss 0.6336 \t Running Acc 2.571 \t Total Acc 0.720 \t Avg Batch Time 0.0012\n",
      "Final  tensor([[0.0000, 0.5124, 0.4876],\n",
      "        [1.0000, 0.4812, 0.5188],\n",
      "        [0.0000, 0.6070, 0.3930],\n",
      "        [0.0000, 0.7252, 0.2748],\n",
      "        [0.0000, 0.6436, 0.3564],\n",
      "        [1.0000, 0.4936, 0.5064],\n",
      "        [0.0000, 0.5200, 0.4800],\n",
      "        [0.0000, 0.5121, 0.4879],\n",
      "        [1.0000, 0.4856, 0.5144],\n",
      "        [1.0000, 0.4854, 0.5146],\n",
      "        [1.0000, 0.4802, 0.5198],\n",
      "        [0.0000, 0.5852, 0.4148],\n",
      "        [0.0000, 0.6583, 0.3417],\n",
      "        [1.0000, 0.5664, 0.4336],\n",
      "        [0.0000, 0.5648, 0.4352],\n",
      "        [1.0000, 0.6145, 0.3855],\n",
      "        [1.0000, 0.6470, 0.3530],\n",
      "        [1.0000, 0.5449, 0.4551],\n",
      "        [0.0000, 0.5886, 0.4114],\n",
      "        [0.0000, 0.5837, 0.4163],\n",
      "        [1.0000, 0.5729, 0.4271],\n",
      "        [1.0000, 0.4453, 0.5547],\n",
      "        [0.0000, 0.4715, 0.5285],\n",
      "        [0.0000, 0.7087, 0.2913],\n",
      "        [0.0000, 0.5580, 0.4420],\n",
      "        [1.0000, 0.5748, 0.4252],\n",
      "        [1.0000, 0.4651, 0.5349],\n",
      "        [0.0000, 0.6443, 0.3557],\n",
      "        [0.0000, 0.5503, 0.4497],\n",
      "        [0.0000, 0.6711, 0.3289],\n",
      "        [0.0000, 0.6164, 0.3836],\n",
      "        [0.0000, 0.5890, 0.4110],\n",
      "        [0.0000, 0.5833, 0.4167],\n",
      "        [1.0000, 0.5479, 0.4521],\n",
      "        [1.0000, 0.4763, 0.5237],\n",
      "        [1.0000, 0.4931, 0.5069],\n",
      "        [0.0000, 0.5710, 0.4290],\n",
      "        [1.0000, 0.4438, 0.5562],\n",
      "        [0.0000, 0.6002, 0.3998],\n",
      "        [0.0000, 0.6437, 0.3563],\n",
      "        [0.0000, 0.5844, 0.4156],\n",
      "        [1.0000, 0.4701, 0.5299],\n",
      "        [1.0000, 0.4373, 0.5627],\n",
      "        [0.0000, 0.5317, 0.4683],\n",
      "        [0.0000, 0.6032, 0.3968],\n",
      "        [1.0000, 0.5006, 0.4994],\n",
      "        [1.0000, 0.4760, 0.5240],\n",
      "        [1.0000, 0.5510, 0.4490],\n",
      "        [1.0000, 0.4371, 0.5629],\n",
      "        [0.0000, 0.5862, 0.4138],\n",
      "        [0.0000, 0.5657, 0.4343],\n",
      "        [1.0000, 0.5017, 0.4983],\n",
      "        [1.0000, 0.5602, 0.4398],\n",
      "        [1.0000, 0.4850, 0.5150],\n",
      "        [1.0000, 0.4707, 0.5293],\n",
      "        [1.0000, 0.4534, 0.5466],\n",
      "        [0.0000, 0.5461, 0.4539],\n",
      "        [0.0000, 0.6837, 0.3163],\n",
      "        [0.0000, 0.7058, 0.2942],\n",
      "        [0.0000, 0.5317, 0.4683],\n",
      "        [0.0000, 0.5445, 0.4555],\n",
      "        [1.0000, 0.4618, 0.5382],\n",
      "        [1.0000, 0.5855, 0.4145],\n",
      "        [1.0000, 0.6058, 0.3942],\n",
      "        [1.0000, 0.5391, 0.4609],\n",
      "        [1.0000, 0.4862, 0.5138],\n",
      "        [1.0000, 0.6359, 0.3641],\n",
      "        [0.0000, 0.6229, 0.3771],\n",
      "        [1.0000, 0.4893, 0.5107],\n",
      "        [0.0000, 0.5658, 0.4342],\n",
      "        [1.0000, 0.4713, 0.5287],\n",
      "        [1.0000, 0.4528, 0.5472],\n",
      "        [1.0000, 0.5118, 0.4882],\n",
      "        [0.0000, 0.5745, 0.4255],\n",
      "        [1.0000, 0.5040, 0.4960],\n",
      "        [1.0000, 0.4634, 0.5366],\n",
      "        [1.0000, 0.4865, 0.5135],\n",
      "        [0.0000, 0.5467, 0.4533],\n",
      "        [1.0000, 0.5198, 0.4802],\n",
      "        [0.0000, 0.5701, 0.4299],\n",
      "        [1.0000, 0.4733, 0.5267],\n",
      "        [1.0000, 0.5095, 0.4905],\n",
      "        [1.0000, 0.6045, 0.3955],\n",
      "        [0.0000, 0.6040, 0.3960],\n",
      "        [0.0000, 0.5669, 0.4331],\n",
      "        [1.0000, 0.5262, 0.4738],\n",
      "        [1.0000, 0.4915, 0.5085],\n",
      "        [0.0000, 0.6126, 0.3874],\n",
      "        [1.0000, 0.5760, 0.4240],\n",
      "        [1.0000, 0.5003, 0.4997],\n",
      "        [1.0000, 0.4880, 0.5120],\n",
      "        [1.0000, 0.4623, 0.5377],\n",
      "        [0.0000, 0.6222, 0.3778],\n",
      "        [1.0000, 0.5111, 0.4889],\n",
      "        [1.0000, 0.5219, 0.4781],\n",
      "        [0.0000, 0.6731, 0.3269],\n",
      "        [1.0000, 0.5253, 0.4747],\n",
      "        [1.0000, 0.5597, 0.4403],\n",
      "        [1.0000, 0.4882, 0.5118],\n",
      "        [0.0000, 0.7228, 0.2772]])\n",
      "Test: Loss 0.6328 \t Acc 0.7200 \t AUC: 0.8636 \t 1/eB 0.3: inf \t 1/eB 0.5: 44.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_17/813438993.py:155: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'test_auc': auc, 'test_1/eB_0.3':1./eB[0],'test_1/eB_0.5':1./eB[1]}\n",
      "/tmp/ipykernel_17/813438993.py:158: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  % (test_res['loss'], test_res['acc'], auc, 1./eB[0], 1./eB[1]))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import json, time\n",
    "# import utils_lorentz\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run(model, epoch, loader, partition, N_EPOCHS=None):\n",
    "    if partition == 'train':\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    res = {'time':0, 'correct':0, 'loss': 0, 'counter': 0, 'acc': 0,\n",
    "           'loss_arr':[], 'correct_arr':[],'label':[],'score':[]}\n",
    "\n",
    "    tik = time.time()\n",
    "    loader_length = len(loader)\n",
    "\n",
    "    for i, (label, p4s, nodes, atom_mask, edge_mask, edges) in tqdm(enumerate(loader)):\n",
    "        if partition == 'train':\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        batch_size, n_nodes, _ = p4s.size()\n",
    "        atom_positions = p4s.view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "        atom_mask = atom_mask.view(batch_size * n_nodes, -1).to(device)\n",
    "        edge_mask = edge_mask.reshape(batch_size * n_nodes * n_nodes, -1).to(device)\n",
    "        nodes = nodes.view(batch_size * n_nodes, -1).to(device,dtype)\n",
    "        edges = [a.to(device) for a in edges]\n",
    "        label = label.to(device, dtype).long()\n",
    "\n",
    "        pred = model(scalars=nodes, x=atom_positions, edges=edges, node_mask=atom_mask,\n",
    "                         edge_mask=edge_mask, n_nodes=n_nodes)\n",
    "\n",
    "        predict = pred.max(1).indices\n",
    "        correct = torch.sum(predict == label).item()\n",
    "        loss = loss_fn(pred, label)\n",
    "\n",
    "        if partition == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        elif partition == 'test':\n",
    "            # save labels and probilities for ROC / AUC\n",
    "            # print(\"Preds \", pred)\n",
    "            score = torch.nn.functional.softmax(pred, dim = -1)\n",
    "            # print(\"Score test \", score)\n",
    "            # raise\n",
    "            res['label'].append(label)\n",
    "            res['score'].append(score)\n",
    "\n",
    "        res['time'] = time.time() - tik\n",
    "        res['correct'] += correct\n",
    "        res['loss'] += loss.item() * batch_size\n",
    "        res['counter'] += batch_size\n",
    "        res['loss_arr'].append(loss.item())\n",
    "        res['correct_arr'].append(correct)\n",
    "\n",
    "        # if i != 0 and i % args.log_interval == 0:\n",
    "\n",
    "    running_loss = sum(res['loss_arr'])/len(res['loss_arr'])\n",
    "    running_acc = sum(res['correct_arr'])/(len(res['correct_arr'])*batch_size)\n",
    "    avg_time = res['time']/res['counter'] * batch_size\n",
    "    tmp_counter = res['counter']\n",
    "    tmp_loss = res['loss'] / tmp_counter\n",
    "    tmp_acc = res['correct'] / tmp_counter\n",
    "\n",
    "    if N_EPOCHS:\n",
    "        print(\">> %s \\t Epoch %d/%d \\t Batch %d/%d \\t Loss %.4f \\t Running Acc %.3f \\t Total Acc %.3f \\t Avg Batch Time %.4f\" %\n",
    "             (partition, epoch + 1, N_EPOCHS, i, loader_length, running_loss, running_acc, tmp_acc, avg_time))\n",
    "    else:\n",
    "        print(\">> %s \\t Loss %.4f \\t Running Acc %.3f \\t Total Acc %.3f \\t Avg Batch Time %.4f\" %\n",
    "             (partition, running_loss, running_acc, tmp_acc, avg_time))\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    # ---------- reduce -----------\n",
    "    if partition == 'test':\n",
    "        res['label'] = torch.cat(res['label']).unsqueeze(-1)\n",
    "        res['score'] = torch.cat(res['score'])\n",
    "        res['score'] = torch.cat((res['label'],res['score']),dim=-1)\n",
    "    res['counter'] = res['counter']\n",
    "    res['loss'] = res['loss'] / res['counter']\n",
    "    res['acc'] = res['correct'] / res['counter']\n",
    "    return res\n",
    "\n",
    "def train(model, res, N_EPOCHS, model_path, log_path):\n",
    "    ### training and validation\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    os.makedirs(log_path, exist_ok=True)\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        train_res = run(model, epoch, dataloaders['train'], partition='train', N_EPOCHS = N_EPOCHS)\n",
    "        print(\"Time: train: %.2f \\t Train loss %.4f \\t Train acc: %.4f\" % (train_res['time'],train_res['loss'],train_res['acc']))\n",
    "        # if epoch % args.val_interval == 0:\n",
    "\n",
    "        # if (args.local_rank == 0):\n",
    "        torch.save(model.state_dict(), os.path.join(model_path, \"checkpoint-epoch-{}.pt\".format(epoch)) )\n",
    "        with torch.no_grad():\n",
    "            val_res = run(model, epoch, dataloaders['val'], partition='val')\n",
    "\n",
    "        # if (args.local_rank == 0): # only master process save\n",
    "        res['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "        res['train_time'].append(train_res['time'])\n",
    "        res['val_time'].append(val_res['time'])\n",
    "        res['train_loss'].append(train_res['loss'])\n",
    "        res['train_acc'].append(train_res['acc'])\n",
    "        res['val_loss'].append(val_res['loss'])\n",
    "        res['val_acc'].append(val_res['acc'])\n",
    "        res['epochs'].append(epoch)\n",
    "\n",
    "        ## save best model\n",
    "        if val_res['acc'] > res['best_val']:\n",
    "            print(\"New best validation model, saving...\")\n",
    "            torch.save(model.state_dict(), os.path.join(model_path,\"best-val-model.pt\"))\n",
    "            res['best_val'] = val_res['acc']\n",
    "            res['best_epoch'] = epoch\n",
    "\n",
    "        print(\"Epoch %d/%d finished.\" % (epoch, N_EPOCHS))\n",
    "        print(\"Train time: %.2f \\t Val time %.2f\" % (train_res['time'], val_res['time']))\n",
    "        print(\"Train loss %.4f \\t Train acc: %.4f\" % (train_res['loss'], train_res['acc']))\n",
    "        print(\"Val loss: %.4f \\t Val acc: %.4f\" % (val_res['loss'], val_res['acc']))\n",
    "        print(\"Best val acc: %.4f at epoch %d.\" % (res['best_val'],  res['best_epoch']))\n",
    "\n",
    "        json_object = json.dumps(res, indent=4)\n",
    "        with open(os.path.join(log_path, \"train-result-epoch{}.json\".format(epoch)), \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "\n",
    "        ## adjust learning rate\n",
    "        if (epoch < 31):\n",
    "            lr_scheduler.step(metrics=val_res['acc'])\n",
    "        else:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = g['lr']*0.5\n",
    "\n",
    "\n",
    "def test(model, res, model_path, log_path):\n",
    "    ### test on best model\n",
    "    best_model = torch.load(os.path.join(model_path, \"best-val-model.pt\"), map_location=device)\n",
    "    model.load_state_dict(best_model)\n",
    "    with torch.no_grad():\n",
    "        test_res = run(model, 0, dataloaders['test'], partition='test')\n",
    "\n",
    "    print(\"Final \", test_res['score'])\n",
    "    pred = test_res['score'].cpu()\n",
    "\n",
    "    np.save(os.path.join(log_path, \"score.npy\"), pred)\n",
    "    fpr, tpr, thres, eB, eS  = buildROC(pred[...,0], pred[...,2])\n",
    "    auc = roc_auc_score(pred[...,0], pred[...,2])\n",
    "\n",
    "    metric = {'test_loss': test_res['loss'], 'test_acc': test_res['acc'],\n",
    "              'test_auc': auc, 'test_1/eB_0.3':1./eB[0],'test_1/eB_0.5':1./eB[1]}\n",
    "    res.update(metric)\n",
    "    print(\"Test: Loss %.4f \\t Acc %.4f \\t AUC: %.4f \\t 1/eB 0.3: %.4f \\t 1/eB 0.5: %.4f\"\\\n",
    "           % (test_res['loss'], test_res['acc'], auc, 1./eB[0], 1./eB[1]))\n",
    "    json_object = json.dumps(res, indent=4)\n",
    "    with open(os.path.join(log_path, \"test-result.json\"), \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    N_EPOCHS = 45 # 60\n",
    "\n",
    "    model_path = \"models/LorentzNet/\"\n",
    "    log_path = \"logs/LorentzNet/\"\n",
    "    # args_init(args)\n",
    "\n",
    "    ### set random seed\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    ### initialize cuda\n",
    "    # dist.init_process_group(backend='nccl')\n",
    "    device = 'cpu' #torch.device(\"cpu\")\n",
    "    dtype = torch.float32\n",
    "\n",
    "    ### load data\n",
    "    # dataloaders = retrieve_dataloaders( batch_size,\n",
    "    #                                     num_data=100000, # use all data\n",
    "    #                                     cache_dir=\"datasets/QMLHEP/quark_gluons/\",\n",
    "    #                                     num_workers=0,\n",
    "    #                                     use_one_hot=True)\n",
    "\n",
    "    ### create parallel model\n",
    "    model = LorentzNet(n_scalar = 1, n_hidden = 4, n_class = 2,\\\n",
    "                       dropout = 0.2, n_layers = 1,\\\n",
    "                       c_weight = 1e-3)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    ### print model and dataset information\n",
    "    # if (args.local_rank == 0):\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"Model Size:\", pytorch_total_params)\n",
    "    for (split, dataloader) in dataloaders.items():\n",
    "        print(f\" {split} samples: {len(dataloader.dataset)}\")\n",
    "\n",
    "    ### optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "\n",
    "    ### lr scheduler\n",
    "    base_scheduler = CosineAnnealingWarmRestarts(optimizer, 4, 2, verbose = False)\n",
    "    lr_scheduler = GradualWarmupScheduler(optimizer, multiplier=1,\\\n",
    "                                                warmup_epoch=5,\\\n",
    "                                                after_scheduler=base_scheduler) ## warmup\n",
    "\n",
    "    ### loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    ### initialize logs\n",
    "    res = {'epochs': [], 'lr' : [],\\\n",
    "           'train_time': [], 'val_time': [],  'train_loss': [], 'val_loss': [],\\\n",
    "           'train_acc': [], 'val_acc': [], 'best_val': 0, 'best_epoch': 0}\n",
    "\n",
    "    ### training and testing\n",
    "    print(\"Training...\")\n",
    "    train(model, res, N_EPOCHS, model_path, log_path)\n",
    "    test(model, res, model_path, log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbd184b",
   "metadata": {
    "id": "gZwcNRHBXLqI",
    "papermill": {
     "duration": 0.052085,
     "end_time": "2024-10-25T09:13:57.614730",
     "exception": false,
     "start_time": "2024-10-25T09:13:57.562645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Equivariant Quantum Neural Networks\n",
    "Now, let's move to quantum machine learning. Given some group $\\mathcal{G}$, one common way to achieve equivariance [6] is to have a quantum neural network of the form $h_{\\theta} = Tr[\\rho \\tilde{O}_{\\theta}]$ such that:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\tilde{O}_{\\theta} \\in Comm(G) = \\{A \\in \\mathbb{C}^{d\\times d} / [A, R(g)] = 0 \\text{ for all } g \\in G\\}\n",
    "\\end{align*}$$\n",
    "\n",
    "To see why, we need to observe that the trace is cyclical, so:\n",
    "\n",
    "$$\\begin{align*}\n",
    "    h_{\\theta} (g\\cdot \\rho) = Tr[R(g)\\rho R^{\\dagger}(g)\\tilde{O}_{\\theta}] = Tr[\\rho R^{\\dagger}(g)\\tilde{O}_{\\theta}R(g)] &= Tr[\\rho R^{\\dagger}(g)R(g)\\tilde{O}_{\\theta}]\\\\\n",
    "    &= Tr[\\rho \\tilde{O}_{\\theta}]\\\\\n",
    "    &= h_{\\theta}(\\rho).\n",
    "\\end{align*}$$\n",
    "\n",
    "Essentially, we are using the Heisenberg picture, where we apply the time evolution to the measurement operator instead of the initial quantum state. When the observable is included in the commutant of $\\mathcal{G}$, we can see how invariance is achieved.\n",
    "\n",
    "The challenge with this approach is that it only works for finite-dimensional and compact groups, like $p4m$, $SO(3)$, etc. The Lorentz group is known to be continuous and non-compact, so it has no finite-dimensional unitary representation. Hence, the approach above is of no use for us. Hopefully, there is another way: instead of baking equivariance directly into the ansatze, we'll do it in the feature space and in the message passing function. When the input is invariant, the message passing becomes equivariant.\n",
    "\n",
    "Similarly to LorentzNet, for standard jet tagging approach, our input is made of $4$-momentum vectors and any associated particle scalar one may wish to include, like color and charge. In fact, in this project, we start with the traditional LorentzNet architecture, but two modifications are made: first, the invariant metric can be extracted from the machine learned algebra; secondly, the $\\phi_e, \\phi_x, \\phi_h$ and $\\phi_m$ - classical parts modeled as classical multilayer perceptrons in Lorentznet, are now substituted by quantum parameterized circuits. Below we show how invariance-equivariance is preserved under this modification.\n",
    "\n",
    "## Infrared safe observables\n",
    "Another interesting bias to incorporate is the infrared and collinear (IRC) safety. An infrared and collinear safe observable is the same in the presence or absence of soft or collinear particles. In [6], an IRC-safe equivariant (classical) GNN was proposed for tagging simulated semi-visible jets from Hidden Valley models, showing superior performance on this data for Beyond the Standard Model (BSM) search.\n",
    "\n",
    "We saw before that in LorentzNet, the message is calculated as:\n",
    "\n",
    "\\begin{equation}\n",
    "m_{ij}^{l} = \\phi_{e}(h_i, h_j, \\psi(||x_{i}^{l} - x_{j}^{l}||^2), \\psi(\\langle x_{i}, x_{j}\\rangle)),\n",
    "\\end{equation}\n",
    "\n",
    "Now, intuitively, an IRC-safe model should give us a graph that stays invariant under any particle corresponding to an infinitesimal emission, or a collinear one. This means that such particles have no influence on other particles in our point cloud. But, how can we do this? Message passing!\n",
    "\n",
    "\\begin{align}\n",
    "\\text{IR safety}:& m^{l}(i,j) \\rightarrow 0 \\text{ as } z \\rightarrow 0,\\\\\n",
    "\\text{C safety}:& m^{l}(i,j + r) = m^{l}(i,j) + m^{l}(i,r) \\text{ as } \\Delta_{jr} \\rightarrow 0,\n",
    "\\end{align}\n",
    "\n",
    "To ensure IR safety, we can not use $z_j$ directly, as it breaks equivariance. We propose, thus, the following substitution:\n",
    "\n",
    "\\begin{equation}\n",
    "m_{ij}^{l} = \\frac{\\langle x_i , x_j\\rangle}{\\sum_{k \\in \\mathcal{N(j)} } \\langle x_i , x_k\\rangle } \\cdot \\phi_{e}(h_i, h_j, \\psi(||x_{i}^{l} - x_{j}^{l}||^2), \\psi(\\langle x_{i}, x_{j}\\rangle)),\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Where $\\langle \\cdot,\\cdot\\rangle$ is the Minkowski inner product, and $\\mathcal{N(j)}$ represents all neighboring particles of $j$. If $j$ is a soft particle, then the Minkowski inner product should be small, thus , which makes the edge connection irrelevant, thus ensuring IR safety. Also, any Lorentz transformation preserves the inner product, so the message should remain symmetry-preserving.\n",
    "\n",
    "\n",
    "## 4.1. Lorentz Equivariant Quantum Block (LEQB)\n",
    "\n",
    "LEQB is the main piece of our model. We aim to fundamentally learn deeper quantum representations of $|\\psi_{x}^{l+1}\\rangle$ and $|\\psi_h^{l+1} \\rangle$ from $|\\psi_{x}^{l} \\rangle$ and $|\\psi_{h}^{l}\\rangle$, where:\n",
    "\n",
    "$$\\begin{align}\n",
    "    |\\psi_{x}^{l+1}\\rangle &= \\mathcal{U}_{x^{l+1}}({x}^{l})|0\\rangle,\\\\\n",
    "    |\\psi_{h}^{l+1}\\rangle &= \\mathcal{U}_{h^{l+1}}({h}^{l})|0\\rangle,\n",
    "\\end{align}$$\n",
    "\n",
    "where $\\mathcal{U_{x^{l}}}, \\mathcal{U_{x^{l+1}}}, \\mathcal{U_{h^{l}}}, \\mathcal{U_{h^{l+1}}}$ are all parameterized standard gate unitaries, or variational circuits. Note that $x^{l}$ are the observables and $h^{l}$ are the particle scalars when $l=0$, but $x^{l} = \\langle \\psi_x | \\mathcal{M} | \\psi_x\\rangle$ and $h^{l} = \\langle \\psi_h | \\mathcal{M} | \\psi_h\\rangle$ for $l > 0$, where $\\mathcal{M}$ is some measurement operator.\n",
    "\n",
    "## 4.2. Theoretical analysis\n",
    "\n",
    "Let's start with the following proposition:\n",
    "\n",
    "> The coordinate embedding $x^{l} = \\{x_1^{l} , x_2^{l} , \\dots , x_n^{l}\\}$ is Lorentz group equivariant and the node embedding $h^{l} = \\{h_1^{l} , h_2^{l}, \\dots , h_n^{l}\\}$ - representing the particle scalars - is Lie group invariant.\n",
    "\n",
    "To prove it, let $Q$ be some Lie group transformation. If the message $m_{ij}^{l}$ is invariant under the action of $Q$ for all $i,j,l,$ then $x_{i}^{l}$ is naturally Lie group equivariant since:\n",
    "\n",
    "$$\\begin{align*}\n",
    "    Q\\cdot x_i^{l+1} &= Q(x_i^{l} + \\sum_{j\\in \\mathcal{N}(i)} x_j^{l}\\cdot \\phi_x (m_{ij}^{l}))\\\\\n",
    "    &= Q\\cdot x_i^{l} + \\sum_{j\\in \\mathcal{N}(i)} Q\\cdot x_j^{l}\\cdot \\phi_x (m_{ij}^{l}),\n",
    "\\end{align*}$$\n",
    "\n",
    "where $Q$ acts under matrix multiplication. The equation above means that acting with $Q$ from the outside is the same as acting with $Q$ from the inside - directly into the node embeddings from the layer before. Then, for the invariance of $m_{ij}^{l}$, since the norm induced by the extracted metric is invariant under the action of $Q$, it holds that $\\|\\|x_{i}^{0} - x_{j}^{0}\\|\\|^2 = \\|\\|Q\\cdot x_{i}^{0} - Q\\cdot x_{j}^{0}\\|\\|^2$, and $\\langle x_{i}^{0}, x_{j}^{0} \\rangle = \\langle Q\\cdot x_{i}^{0}, Q\\cdot x_{j}^{0} \\rangle$. Since $m_{ij}^{l+1} = \\phi_e(h_i^{l}, h_j^{l}, \\|\\|x_{i}^{l} - x_{j}^{l}\\|\\|^2, \\langle x_{i}^{l}, x_{j}^{l} \\rangle)$, and the norm and the inner product are already invariant, we just have to show that $h^{l}$ is also invariant, since:\n",
    "\n",
    "$$\\begin{equation*}\n",
    "    h_i^{l+1} = h_i^{l} + \\phi_h (h_i^{l}, \\sum_{j\\in \\mathcal{N}(i)} w_{ij} m_{ij}^{l}).\n",
    "\\end{equation*}$$\n",
    "    \n",
    "For layer $l=0$, $h_{i}^{l}$ is already invariant (since it contains information only about the particle scalars). Then, $m_{ij}^{l+1}$ will be invariant, since all of its inputs are also invariant, and we follow the same logic for $x_{i}^{l+1}$. Given that these properties of $x,h,m$ hold for the first layer and the next, we reach the conclusion recursively.\n",
    "\n",
    "Having a quick glance at the discussion we had about groups, equivariance, particles and quantum machine learning, we are getting a hint that the marriage between Physics and symmetries is actually deep. Indeed it is! To quote Philip Anderson, who won the 1977 Nobel prize “for their fundamental theoretical investigations of the electronic structure of magnetic and disordered systems”:\n",
    "\n",
    "> It is only slightly overstating the case to say that physics is the study of symmetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c63185a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:57.724059Z",
     "iopub.status.busy": "2024-10-25T09:13:57.723161Z",
     "iopub.status.idle": "2024-10-25T09:13:59.772758Z",
     "shell.execute_reply": "2024-10-25T09:13:59.771812Z"
    },
    "id": "3T8yKHYCZbPk",
    "papermill": {
     "duration": 2.107335,
     "end_time": "2024-10-25T09:13:59.775274",
     "exception": false,
     "start_time": "2024-10-25T09:13:57.667939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "n_qubits = 4\n",
    "\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n",
    "# dev = qml.device(\"qiskit.aer\", wires=n_qubits)\n",
    "\n",
    "\n",
    "def H_layer(nqubits):\n",
    "    \"\"\"Layer of single-qubit Hadamard gates.\n",
    "    \"\"\"\n",
    "    for idx in range(nqubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "\n",
    "def RY_layer(w):\n",
    "    \"\"\"Layer of parametrized qubit rotations around the y axis.\n",
    "    \"\"\"\n",
    "    for idx, element in enumerate(w):\n",
    "        qml.RY(element, wires=idx)\n",
    "\n",
    "def RY_RX_layer(weights):\n",
    "    \"\"\"Applies a layer of parametrized RY and RX rotations.\"\"\"\n",
    "    for i, w in enumerate(weights):\n",
    "        qml.RY(w, wires=i)\n",
    "        qml.RX(w, wires=i)\n",
    "\n",
    "def full_entangling_layer(n_qubits):\n",
    "    \"\"\"Applies CNOT gates between all pairs of qubits.\"\"\"\n",
    "    for i in range(n_qubits):\n",
    "        for j in range(i+1, n_qubits):\n",
    "            qml.CNOT(wires=[i, j])\n",
    "\n",
    "def entangling_layer(nqubits):\n",
    "    \"\"\"Layer of CNOTs followed by another shifted layer of CNOT.\n",
    "    \"\"\"\n",
    "    # In other words it should apply something like :\n",
    "    # CNOT  CNOT  CNOT  CNOT...  CNOT\n",
    "    #   CNOT  CNOT  CNOT...  CNOT\n",
    "    for i in range(nqubits - 1):\n",
    "        qml.CRZ(np.pi / 2, wires=[i, i + 1])\n",
    "    for i in range(0, nqubits - 1, 2):  # Loop over even indices: i=0,2,...N-2\n",
    "        qml.SWAP(wires=[i, i + 1])\n",
    "    for i in range(1, nqubits - 1, 2):  # Loop over odd indices:  i=1,3,...N-3\n",
    "        qml.SWAP(wires=[i, i + 1])\n",
    "\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_net(q_input_features, q_weights_flat, q_depth, n_qubits):\n",
    "    \"\"\"\n",
    "    The variational quantum circuit.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape weights\n",
    "    q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
    "\n",
    "    # Start from state |+> , unbiased w.r.t. |0> and |1>\n",
    "    H_layer(n_qubits)\n",
    "\n",
    "    # Embed features in the quantum node\n",
    "    # RY_layer(q_input_features)\n",
    "    qml.AngleEmbedding(features=q_input_features, wires=range(n_qubits), rotation='Z')\n",
    "\n",
    "    # Sequence of trainable variational layers\n",
    "    # for k in range(q_depth):\n",
    "    #     entangling_layer(n_qubits)\n",
    "    #     RY_RX_layer(q_weights[k])\n",
    "    #     # RY_layer(q_weights[k])\n",
    "    for k in range(q_depth):\n",
    "        if k % 2 == 0:\n",
    "            entangling_layer(n_qubits)\n",
    "            RY_layer(q_weights[k])\n",
    "        else:\n",
    "            full_entangling_layer(n_qubits)\n",
    "            RY_RX_layer(q_weights[k])\n",
    "\n",
    "    # Expectation values in the Z basis\n",
    "    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(n_qubits)]\n",
    "    return tuple(exp_vals)\n",
    "\n",
    "\n",
    "class DressedQuantumNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Torch module implementing the *dressed* quantum net.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_qubits, q_depth = 1, q_delta=0.001):\n",
    "        \"\"\"\n",
    "        Definition of the *dressed* layout.\n",
    "        \"\"\"\n",
    "        print('n_qubits: ', n_qubits)\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.q_depth = q_depth\n",
    "        self.q_params = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits))\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        \"\"\"\n",
    "        Optimized forward pass to reduce runtime.\n",
    "        \"\"\"\n",
    "\n",
    "        # Quantum Embedding (U(X))\n",
    "        q_in = torch.tanh(input_features) * np.pi / 2.0\n",
    "\n",
    "        # Preallocate output tensor\n",
    "        batch_size = q_in.shape[0]\n",
    "        q_out = torch.zeros(batch_size, self.n_qubits, device=q_in.device)\n",
    "\n",
    "        # Vectorized execution\n",
    "        for i, elem in enumerate(q_in):\n",
    "            q_out_elem = torch.hstack(quantum_net(elem, self.q_params, self.q_depth, self.n_qubits)).float()\n",
    "            q_out[i] = q_out_elem\n",
    "\n",
    "        return q_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e651aba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:13:59.934808Z",
     "iopub.status.busy": "2024-10-25T09:13:59.934112Z",
     "iopub.status.idle": "2024-10-25T09:13:59.960660Z",
     "shell.execute_reply": "2024-10-25T09:13:59.959551Z"
    },
    "id": "9sBE05_9XLqJ",
    "papermill": {
     "duration": 0.082526,
     "end_time": "2024-10-25T09:13:59.962696",
     "exception": false,
     "start_time": "2024-10-25T09:13:59.880170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "\n",
    "\"\"\"\n",
    "    Lie-Equivariant Quantum Block (LEQB).\n",
    "\n",
    "        - Given the Lie generators found (i.e.: through LieGAN, oracle-preserving latent flow, or some other approach\n",
    "          that we develop further), once the metric tensor J is found via the equation:\n",
    "\n",
    "                          L.J + J.(L^T) = 0,\n",
    "\n",
    "          we just have to specify the metric to make the model symmetry-preserving to the corresponding Lie group.\n",
    "          In the cells below, we can see how the model preserves symmetries (starting with the default Lorentz group),\n",
    "          and when we change J to some other metric (Euclidean, for example), Lorentz boosts **break** equivariance, while other\n",
    "          transformations preserve it (rotations, for the example shown in the cells below)\n",
    "\"\"\"\n",
    "class LEQB(nn.Module):\n",
    "    def __init__(self, n_input, n_output, n_hidden, n_node_attr=0,\n",
    "                 dropout = 0., c_weight=1.0, last_layer=False, A=None, include_x=False):\n",
    "        super(LEQB, self).__init__()\n",
    "        self.c_weight = c_weight\n",
    "        self.dimension_reducer = nn.Linear(10, 4) # New linear layer for dimension reduction\n",
    "        self.dimension_reducer2 = nn.Linear(9, 4) # New linear layer for dimension reduction for phi_h\n",
    "        n_edge_attr = 2 if not include_x else 10 # dims for Minkowski norm & inner product\n",
    "        # With include_X = False, not include_x becomes True, so the value of n_edge_attr is 2. n_input = n_hidden = 4\n",
    "        print('Input size of phi_e: ', n_input)\n",
    "        self.include_x = include_x\n",
    "\n",
    "        \"\"\"\n",
    "            phi_e: input size: n_qubits -> output size: n_qubits\n",
    "            n_hidden has to be equal to n_input,\n",
    "            but this is just considering that this is a simple working example.\n",
    "        \"\"\"\n",
    "        self.phi_e = DressedQuantumNet(n_input)\n",
    "#         self.phi_e = nn.Sequential(\n",
    "#             nn.Linear(n_input, n_hidden, bias=False),  # n_input * 2 + n_edge_attr\n",
    "#             nn.BatchNorm1d(n_hidden),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(n_hidden, n_hidden),\n",
    "#             nn.ReLU())\n",
    "\n",
    "        n_hidden = n_input # n_input * 2 + n_edge_attr\n",
    "        self.phi_h = nn.Sequential(\n",
    "            nn.Linear(n_hidden + n_input + n_node_attr, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_output))\n",
    "\n",
    "#         self.phi_h = DressedQuantumNet(n_hidden)\n",
    "\n",
    "        layer = nn.Linear(n_hidden, 1, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(layer.weight, gain=0.001)\n",
    "\n",
    "        self.phi_x = nn.Sequential(\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            layer)\n",
    "        \n",
    "#         self.phi_x = nn.Sequential(\n",
    "#             DressedQuantumNet(n_hidden),\n",
    "#             layer)\n",
    "\n",
    "#         self.phi_m = nn.Sequential(\n",
    "#             DressedQuantumNet(n_hidden),\n",
    "#             nn.Linear(n_hidden, 1),\n",
    "#             nn.Sigmoid())\n",
    "        \n",
    "        self.phi_m = nn.Sequential(\n",
    "            nn.Linear(n_hidden, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "        # self.phi_e = nn.Sequential(\n",
    "        #     nn.Linear(n_input * 2 + n_edge_attr, n_hidden, bias=False),\n",
    "        #     nn.BatchNorm1d(n_hidden),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(n_hidden, n_hidden),\n",
    "        #     nn.ReLU())\n",
    "\n",
    "        self.last_layer = last_layer\n",
    "        if last_layer:\n",
    "            del self.phi_x\n",
    "\n",
    "        self.A = A\n",
    "        self.norm_fn = normA_fn(A) if A is not None else normsq4\n",
    "        self.dot_fn = dotA_fn(A) if A is not None else dotsq4\n",
    "\n",
    "    def m_model(self, hi, hj, norms, dots):\n",
    "        out = torch.cat([hi, hj, norms, dots], dim=1)\n",
    "        out = self.dimension_reducer(out) # extra\n",
    "        # print(\"Before embedding to |psi> : \", out)\n",
    "        out = self.phi_e(out).squeeze(0)\n",
    "        w = self.phi_m(out)\n",
    "        out = out * w\n",
    "        return out\n",
    "\n",
    "    def m_model_extended(self, hi, hj, norms, dots, xi, xj):\n",
    "        out = torch.cat([hi, hj, norms, dots, xi, xj], dim=1)\n",
    "        out = self.dimension_reducer(out) # extra\n",
    "        out = self.phi_e(out).squeeze(0)\n",
    "        w = self.phi_m(out)\n",
    "        out = out * w\n",
    "        return out\n",
    "\n",
    "    def h_model(self, h, edges, m, node_attr):\n",
    "        i, j = edges\n",
    "        agg = unsorted_segment_sum(m, i, num_segments=h.size(0))\n",
    "        agg = torch.cat([h, agg, node_attr], dim=1)\n",
    "        #agg = self.dimension_reducer2(agg) # extra for phi_h\n",
    "        out = h + self.phi_h(agg)\n",
    "        return out\n",
    "\n",
    "    def x_model(self, x, edges, x_diff, m):\n",
    "        i, j = edges\n",
    "        trans = x_diff * self.phi_x(m)\n",
    "        # From https://github.com/vgsatorras/egnn\n",
    "        # This is never activated but just in case it explosed it may save the train\n",
    "        # From https://github.com/vgsatorras/egnn\n",
    "        # This is never activated but just in case it explosed it may save the train\n",
    "        trans = torch.clamp(trans, min=-100, max=100)\n",
    "        agg = unsorted_segment_mean(trans, i, num_segments=x.size(0))\n",
    "        x = x + agg * self.c_weight\n",
    "        return x\n",
    "\n",
    "    def minkowski_feats(self, edges, x):\n",
    "        i, j = edges\n",
    "        x_diff = x[i] - x[j]\n",
    "        norms = self.norm_fn(x_diff).unsqueeze(1)\n",
    "        dots = self.dot_fn(x[i], x[j]).unsqueeze(1)\n",
    "        norms, dots = psi(norms), psi(dots)\n",
    "        return norms, dots, x_diff\n",
    "\n",
    "    def forward(self, h, x, edges, node_attr=None):\n",
    "        i, j = edges\n",
    "        norms, dots, x_diff = self.minkowski_feats(edges, x)\n",
    "\n",
    "        if self.include_x:\n",
    "            m = self.m_model_extended(h[i], h[j], norms, dots, x[i], x[j])\n",
    "        else:\n",
    "            m = self.m_model(h[i], h[j], norms, dots) # [B*N, hidden]\n",
    "        if not self.last_layer:\n",
    "            x = self.x_model(x, edges, x_diff, m)\n",
    "        h = self.h_model(h, edges, m, node_attr)\n",
    "        return h, x, m\n",
    "\n",
    "class LieEQGNN(nn.Module):\n",
    "    r''' Implementation of LorentzNet.\n",
    "\n",
    "    Args:\n",
    "        - `n_scalar` (int): number of input scalars.\n",
    "        - `n_hidden` (int): dimension of latent space.\n",
    "        - `n_class`  (int): number of output classes.\n",
    "        - `n_layers` (int): number of LEQB layers.\n",
    "        - `c_weight` (float): weight c in the x_model.\n",
    "        - `dropout`  (float): dropout rate.\n",
    "    '''\n",
    "    def __init__(self, n_scalar, n_hidden, n_class = 2, n_layers = 6, c_weight = 1e-3, dropout = 0., A=None, include_x=False):\n",
    "        super(LieEQGNN, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Linear(n_scalar, n_hidden)\n",
    "        self.LEQBs = nn.ModuleList([LEQB(self.n_hidden, self.n_hidden, self.n_hidden,\n",
    "                                    n_node_attr=n_scalar, dropout=dropout,\n",
    "                                    c_weight=c_weight, last_layer=(i==n_layers-1), A=A, include_x=include_x)\n",
    "                                    for i in range(n_layers)])\n",
    "        self.graph_dec = nn.Sequential(nn.Linear(self.n_hidden, self.n_hidden),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(dropout),\n",
    "                                       nn.Linear(self.n_hidden, n_class)) # classification\n",
    "\n",
    "    def forward(self, scalars, x, edges, node_mask, edge_mask, n_nodes):\n",
    "        h = self.embedding(scalars)\n",
    "\n",
    "        # print(\"h before (just the first particle): \\n\", h[0].cpu().detach().numpy())\n",
    "        for i in range(self.n_layers):\n",
    "            h, x, _ = self.LEQBs[i](h, x, edges, node_attr=scalars)\n",
    "\n",
    "        # print(\"h after (just the first particle): \\n\", h[0].cpu().detach().numpy())\n",
    "\n",
    "        h = h * node_mask\n",
    "        h = h.view(-1, n_nodes, self.n_hidden)\n",
    "        h = torch.mean(h, dim=1)\n",
    "        pred = self.graph_dec(h)\n",
    "        return pred.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4594f833",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T09:14:00.070610Z",
     "iopub.status.busy": "2024-10-25T09:14:00.070212Z",
     "iopub.status.idle": "2024-10-25T17:35:22.405010Z",
     "shell.execute_reply": "2024-10-25T17:35:22.403767Z"
    },
    "id": "sCLi_VJSZiEE",
    "outputId": "54936a42-d9e0-4fc5-f638-c477eea493f7",
    "papermill": {
     "duration": 30082.393607,
     "end_time": "2024-10-25T17:35:22.409726",
     "exception": false,
     "start_time": "2024-10-25T09:14:00.016119",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size of phi_e:  4\n",
      "n_qubits:  4\n",
      "Model Size: 199\n",
      " train samples: 800\n",
      " val samples: 100\n",
      " test samples: 100\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:35, 10.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 1/55 \t Batch 49/50 \t Loss 0.7503 \t Running Acc 0.491 \t Total Acc 0.491 \t Avg Batch Time 10.3004\n",
      "Time: train: 515.02 \t Train loss 0.7503 \t Train acc: 0.4913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.7267 \t Running Acc 1.857 \t Total Acc 0.520 \t Avg Batch Time 1.5878\n",
      "New best validation model, saving...\n",
      "Epoch 0/55 finished.\n",
      "Train time: 515.02 \t Val time 39.70\n",
      "Train loss 0.7503 \t Train acc: 0.4913\n",
      "Val loss: 0.7247 \t Val acc: 0.5200\n",
      "Best val acc: 0.5200 at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:33, 10.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 2/55 \t Batch 49/50 \t Loss 0.7358 \t Running Acc 0.491 \t Total Acc 0.491 \t Avg Batch Time 10.2676\n",
      "Time: train: 513.38 \t Train loss 0.7358 \t Train acc: 0.4913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.7170 \t Running Acc 1.857 \t Total Acc 0.520 \t Avg Batch Time 1.5675\n",
      "Epoch 1/55 finished.\n",
      "Train time: 513.38 \t Val time 39.19\n",
      "Train loss 0.7358 \t Train acc: 0.4913\n",
      "Val loss: 0.7152 \t Val acc: 0.5200\n",
      "Best val acc: 0.5200 at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:30, 10.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 3/55 \t Batch 49/50 \t Loss 0.7241 \t Running Acc 0.491 \t Total Acc 0.491 \t Avg Batch Time 10.2134\n",
      "Time: train: 510.67 \t Train loss 0.7241 \t Train acc: 0.4913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.7060 \t Running Acc 1.857 \t Total Acc 0.520 \t Avg Batch Time 1.5801\n",
      "Epoch 2/55 finished.\n",
      "Train time: 510.67 \t Val time 39.50\n",
      "Train loss 0.7241 \t Train acc: 0.4913\n",
      "Val loss: 0.7045 \t Val acc: 0.5200\n",
      "Best val acc: 0.5200 at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:29, 10.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 4/55 \t Batch 49/50 \t Loss 0.7143 \t Running Acc 0.491 \t Total Acc 0.491 \t Avg Batch Time 10.1999\n",
      "Time: train: 510.00 \t Train loss 0.7143 \t Train acc: 0.4913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6969 \t Running Acc 1.857 \t Total Acc 0.520 \t Avg Batch Time 1.5929\n",
      "Epoch 3/55 finished.\n",
      "Train time: 510.00 \t Val time 39.82\n",
      "Train loss 0.7143 \t Train acc: 0.4913\n",
      "Val loss: 0.6957 \t Val acc: 0.5200\n",
      "Best val acc: 0.5200 at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:31, 10.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 5/55 \t Batch 49/50 \t Loss 0.7016 \t Running Acc 0.491 \t Total Acc 0.491 \t Avg Batch Time 10.2350\n",
      "Time: train: 511.75 \t Train loss 0.7016 \t Train acc: 0.4913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6893 \t Running Acc 1.857 \t Total Acc 0.520 \t Avg Batch Time 1.5879\n",
      "Epoch 4/55 finished.\n",
      "Train time: 511.75 \t Val time 39.70\n",
      "Train loss 0.7016 \t Train acc: 0.4913\n",
      "Val loss: 0.6881 \t Val acc: 0.5200\n",
      "Best val acc: 0.5200 at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:32, 10.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 6/55 \t Batch 49/50 \t Loss 0.6921 \t Running Acc 0.506 \t Total Acc 0.506 \t Avg Batch Time 10.2437\n",
      "Time: train: 512.19 \t Train loss 0.6921 \t Train acc: 0.5062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6839 \t Running Acc 1.857 \t Total Acc 0.520 \t Avg Batch Time 1.5687\n",
      "Epoch 5/55 finished.\n",
      "Train time: 512.19 \t Val time 39.22\n",
      "Train loss 0.6921 \t Train acc: 0.5062\n",
      "Val loss: 0.6824 \t Val acc: 0.5200\n",
      "Best val acc: 0.5200 at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:30, 10.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 7/55 \t Batch 49/50 \t Loss 0.6900 \t Running Acc 0.514 \t Total Acc 0.514 \t Avg Batch Time 10.2135\n",
      "Time: train: 510.68 \t Train loss 0.6900 \t Train acc: 0.5138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6808 \t Running Acc 1.857 \t Total Acc 0.520 \t Avg Batch Time 1.5689\n",
      "Epoch 6/55 finished.\n",
      "Train time: 510.68 \t Val time 39.22\n",
      "Train loss 0.6900 \t Train acc: 0.5138\n",
      "Val loss: 0.6792 \t Val acc: 0.5200\n",
      "Best val acc: 0.5200 at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:27, 10.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 8/55 \t Batch 49/50 \t Loss 0.6872 \t Running Acc 0.499 \t Total Acc 0.499 \t Avg Batch Time 10.1566\n",
      "Time: train: 507.83 \t Train loss 0.6872 \t Train acc: 0.4988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6799 \t Running Acc 1.857 \t Total Acc 0.520 \t Avg Batch Time 1.5668\n",
      "Epoch 7/55 finished.\n",
      "Train time: 507.83 \t Val time 39.17\n",
      "Train loss 0.6872 \t Train acc: 0.4988\n",
      "Val loss: 0.6782 \t Val acc: 0.5200\n",
      "Best val acc: 0.5200 at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:26, 10.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 9/55 \t Batch 49/50 \t Loss 0.6828 \t Running Acc 0.530 \t Total Acc 0.530 \t Avg Batch Time 10.1313\n",
      "Time: train: 506.56 \t Train loss 0.6828 \t Train acc: 0.5300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6718 \t Running Acc 1.857 \t Total Acc 0.520 \t Avg Batch Time 1.5776\n",
      "Epoch 8/55 finished.\n",
      "Train time: 506.56 \t Val time 39.44\n",
      "Train loss 0.6828 \t Train acc: 0.5300\n",
      "Val loss: 0.6694 \t Val acc: 0.5200\n",
      "Best val acc: 0.5200 at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:25, 10.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 10/55 \t Batch 49/50 \t Loss 0.6763 \t Running Acc 0.573 \t Total Acc 0.573 \t Avg Batch Time 10.1133\n",
      "Time: train: 505.66 \t Train loss 0.6763 \t Train acc: 0.5725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6624 \t Running Acc 2.000 \t Total Acc 0.560 \t Avg Batch Time 1.5667\n",
      "New best validation model, saving...\n",
      "Epoch 9/55 finished.\n",
      "Train time: 505.66 \t Val time 39.17\n",
      "Train loss 0.6763 \t Train acc: 0.5725\n",
      "Val loss: 0.6591 \t Val acc: 0.5600\n",
      "Best val acc: 0.5600 at epoch 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:26, 10.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 11/55 \t Batch 49/50 \t Loss 0.6651 \t Running Acc 0.630 \t Total Acc 0.630 \t Avg Batch Time 10.1351\n",
      "Time: train: 506.76 \t Train loss 0.6651 \t Train acc: 0.6300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6520 \t Running Acc 2.250 \t Total Acc 0.630 \t Avg Batch Time 1.5601\n",
      "New best validation model, saving...\n",
      "Epoch 10/55 finished.\n",
      "Train time: 506.76 \t Val time 39.00\n",
      "Train loss 0.6651 \t Train acc: 0.6300\n",
      "Val loss: 0.6473 \t Val acc: 0.6300\n",
      "Best val acc: 0.6300 at epoch 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:26, 10.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 12/55 \t Batch 49/50 \t Loss 0.6528 \t Running Acc 0.644 \t Total Acc 0.644 \t Avg Batch Time 10.1347\n",
      "Time: train: 506.73 \t Train loss 0.6528 \t Train acc: 0.6438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6449 \t Running Acc 2.607 \t Total Acc 0.730 \t Avg Batch Time 1.5590\n",
      "New best validation model, saving...\n",
      "Epoch 11/55 finished.\n",
      "Train time: 506.73 \t Val time 38.97\n",
      "Train loss 0.6528 \t Train acc: 0.6438\n",
      "Val loss: 0.6396 \t Val acc: 0.7300\n",
      "Best val acc: 0.7300 at epoch 11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:24, 10.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 13/55 \t Batch 49/50 \t Loss 0.6506 \t Running Acc 0.655 \t Total Acc 0.655 \t Avg Batch Time 10.0863\n",
      "Time: train: 504.31 \t Train loss 0.6506 \t Train acc: 0.6550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6409 \t Running Acc 2.857 \t Total Acc 0.800 \t Avg Batch Time 1.5549\n",
      "New best validation model, saving...\n",
      "Epoch 12/55 finished.\n",
      "Train time: 504.31 \t Val time 38.87\n",
      "Train loss 0.6506 \t Train acc: 0.6550\n",
      "Val loss: 0.6352 \t Val acc: 0.8000\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:24, 10.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 14/55 \t Batch 49/50 \t Loss 0.6465 \t Running Acc 0.656 \t Total Acc 0.656 \t Avg Batch Time 10.0949\n",
      "Time: train: 504.74 \t Train loss 0.6465 \t Train acc: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6385 \t Running Acc 2.821 \t Total Acc 0.790 \t Avg Batch Time 1.5543\n",
      "Epoch 13/55 finished.\n",
      "Train time: 504.74 \t Val time 38.86\n",
      "Train loss 0.6465 \t Train acc: 0.6562\n",
      "Val loss: 0.6327 \t Val acc: 0.7900\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:24, 10.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 15/55 \t Batch 49/50 \t Loss 0.6413 \t Running Acc 0.670 \t Total Acc 0.670 \t Avg Batch Time 10.0875\n",
      "Time: train: 504.38 \t Train loss 0.6413 \t Train acc: 0.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6371 \t Running Acc 2.857 \t Total Acc 0.800 \t Avg Batch Time 1.5612\n",
      "Epoch 14/55 finished.\n",
      "Train time: 504.38 \t Val time 39.03\n",
      "Train loss 0.6413 \t Train acc: 0.6700\n",
      "Val loss: 0.6310 \t Val acc: 0.8000\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:26, 10.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 16/55 \t Batch 49/50 \t Loss 0.6409 \t Running Acc 0.667 \t Total Acc 0.667 \t Avg Batch Time 10.1239\n",
      "Time: train: 506.19 \t Train loss 0.6409 \t Train acc: 0.6675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6366 \t Running Acc 2.857 \t Total Acc 0.800 \t Avg Batch Time 1.5719\n",
      "Epoch 15/55 finished.\n",
      "Train time: 506.19 \t Val time 39.30\n",
      "Train loss 0.6409 \t Train acc: 0.6675\n",
      "Val loss: 0.6305 \t Val acc: 0.8000\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:27, 10.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 17/55 \t Batch 49/50 \t Loss 0.6347 \t Running Acc 0.690 \t Total Acc 0.690 \t Avg Batch Time 10.1427\n",
      "Time: train: 507.13 \t Train loss 0.6347 \t Train acc: 0.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6292 \t Running Acc 2.750 \t Total Acc 0.770 \t Avg Batch Time 1.5669\n",
      "Epoch 16/55 finished.\n",
      "Train time: 507.13 \t Val time 39.17\n",
      "Train loss 0.6347 \t Train acc: 0.6900\n",
      "Val loss: 0.6221 \t Val acc: 0.7700\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:27, 10.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 18/55 \t Batch 49/50 \t Loss 0.6301 \t Running Acc 0.682 \t Total Acc 0.682 \t Avg Batch Time 10.1440\n",
      "Time: train: 507.20 \t Train loss 0.6301 \t Train acc: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6188 \t Running Acc 2.679 \t Total Acc 0.750 \t Avg Batch Time 1.5717\n",
      "Epoch 17/55 finished.\n",
      "Train time: 507.20 \t Val time 39.29\n",
      "Train loss 0.6301 \t Train acc: 0.6825\n",
      "Val loss: 0.6105 \t Val acc: 0.7500\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:26, 10.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 19/55 \t Batch 49/50 \t Loss 0.6170 \t Running Acc 0.703 \t Total Acc 0.703 \t Avg Batch Time 10.1280\n",
      "Time: train: 506.40 \t Train loss 0.6170 \t Train acc: 0.7025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6086 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5630\n",
      "Epoch 18/55 finished.\n",
      "Train time: 506.40 \t Val time 39.07\n",
      "Train loss 0.6170 \t Train acc: 0.7025\n",
      "Val loss: 0.5989 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:25, 10.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 20/55 \t Batch 49/50 \t Loss 0.6134 \t Running Acc 0.700 \t Total Acc 0.700 \t Avg Batch Time 10.1004\n",
      "Time: train: 505.02 \t Train loss 0.6134 \t Train acc: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6021 \t Running Acc 2.643 \t Total Acc 0.740 \t Avg Batch Time 1.5611\n",
      "Epoch 19/55 finished.\n",
      "Train time: 505.02 \t Val time 39.03\n",
      "Train loss 0.6134 \t Train acc: 0.7000\n",
      "Val loss: 0.5913 \t Val acc: 0.7400\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:24, 10.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 21/55 \t Batch 49/50 \t Loss 0.6025 \t Running Acc 0.731 \t Total Acc 0.731 \t Avg Batch Time 10.0954\n",
      "Time: train: 504.77 \t Train loss 0.6025 \t Train acc: 0.7312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5967 \t Running Acc 2.750 \t Total Acc 0.770 \t Avg Batch Time 1.5600\n",
      "Epoch 20/55 finished.\n",
      "Train time: 504.77 \t Val time 39.00\n",
      "Train loss 0.6025 \t Train acc: 0.7312\n",
      "Val loss: 0.5849 \t Val acc: 0.7700\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:29, 10.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 22/55 \t Batch 49/50 \t Loss 0.5928 \t Running Acc 0.721 \t Total Acc 0.721 \t Avg Batch Time 10.1979\n",
      "Time: train: 509.89 \t Train loss 0.5928 \t Train acc: 0.7212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5901 \t Running Acc 2.679 \t Total Acc 0.750 \t Avg Batch Time 1.5834\n",
      "Epoch 21/55 finished.\n",
      "Train time: 509.89 \t Val time 39.58\n",
      "Train loss 0.5928 \t Train acc: 0.7212\n",
      "Val loss: 0.5768 \t Val acc: 0.7500\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:29, 10.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 23/55 \t Batch 49/50 \t Loss 0.5829 \t Running Acc 0.714 \t Total Acc 0.714 \t Avg Batch Time 10.1938\n",
      "Time: train: 509.69 \t Train loss 0.5829 \t Train acc: 0.7137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5815 \t Running Acc 2.679 \t Total Acc 0.750 \t Avg Batch Time 1.5666\n",
      "Epoch 22/55 finished.\n",
      "Train time: 509.69 \t Val time 39.16\n",
      "Train loss 0.5829 \t Train acc: 0.7137\n",
      "Val loss: 0.5673 \t Val acc: 0.7500\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:31, 10.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 24/55 \t Batch 49/50 \t Loss 0.5773 \t Running Acc 0.721 \t Total Acc 0.721 \t Avg Batch Time 10.2395\n",
      "Time: train: 511.98 \t Train loss 0.5773 \t Train acc: 0.7212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:40,  5.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5750 \t Running Acc 2.643 \t Total Acc 0.740 \t Avg Batch Time 1.6095\n",
      "Epoch 23/55 finished.\n",
      "Train time: 511.98 \t Val time 40.24\n",
      "Train loss 0.5773 \t Train acc: 0.7212\n",
      "Val loss: 0.5598 \t Val acc: 0.7400\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:28, 10.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 25/55 \t Batch 49/50 \t Loss 0.5722 \t Running Acc 0.724 \t Total Acc 0.724 \t Avg Batch Time 10.1727\n",
      "Time: train: 508.63 \t Train loss 0.5722 \t Train acc: 0.7238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5719 \t Running Acc 2.679 \t Total Acc 0.750 \t Avg Batch Time 1.5781\n",
      "Epoch 24/55 finished.\n",
      "Train time: 508.63 \t Val time 39.45\n",
      "Train loss 0.5722 \t Train acc: 0.7238\n",
      "Val loss: 0.5558 \t Val acc: 0.7500\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:26, 10.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 26/55 \t Batch 49/50 \t Loss 0.5744 \t Running Acc 0.720 \t Total Acc 0.720 \t Avg Batch Time 10.1312\n",
      "Time: train: 506.56 \t Train loss 0.5744 \t Train acc: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5690 \t Running Acc 2.750 \t Total Acc 0.770 \t Avg Batch Time 1.5717\n",
      "Epoch 25/55 finished.\n",
      "Train time: 506.56 \t Val time 39.29\n",
      "Train loss 0.5744 \t Train acc: 0.7200\n",
      "Val loss: 0.5523 \t Val acc: 0.7700\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:28, 10.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 27/55 \t Batch 49/50 \t Loss 0.5729 \t Running Acc 0.703 \t Total Acc 0.703 \t Avg Batch Time 10.1623\n",
      "Time: train: 508.12 \t Train loss 0.5729 \t Train acc: 0.7025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5696 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5799\n",
      "Epoch 26/55 finished.\n",
      "Train time: 508.12 \t Val time 39.50\n",
      "Train loss 0.5729 \t Train acc: 0.7025\n",
      "Val loss: 0.5523 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:30, 10.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 28/55 \t Batch 49/50 \t Loss 0.5709 \t Running Acc 0.724 \t Total Acc 0.724 \t Avg Batch Time 10.2093\n",
      "Time: train: 510.47 \t Train loss 0.5709 \t Train acc: 0.7238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5681 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5608\n",
      "Epoch 27/55 finished.\n",
      "Train time: 510.47 \t Val time 39.02\n",
      "Train loss 0.5709 \t Train acc: 0.7238\n",
      "Val loss: 0.5506 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:23, 10.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 29/55 \t Batch 49/50 \t Loss 0.5772 \t Running Acc 0.720 \t Total Acc 0.720 \t Avg Batch Time 10.0787\n",
      "Time: train: 503.94 \t Train loss 0.5772 \t Train acc: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5670 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5580\n",
      "Epoch 28/55 finished.\n",
      "Train time: 503.94 \t Val time 38.95\n",
      "Train loss 0.5772 \t Train acc: 0.7200\n",
      "Val loss: 0.5493 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:25, 10.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 30/55 \t Batch 49/50 \t Loss 0.5720 \t Running Acc 0.711 \t Total Acc 0.711 \t Avg Batch Time 10.1199\n",
      "Time: train: 505.99 \t Train loss 0.5720 \t Train acc: 0.7113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5663 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5575\n",
      "Epoch 29/55 finished.\n",
      "Train time: 505.99 \t Val time 38.94\n",
      "Train loss 0.5720 \t Train acc: 0.7113\n",
      "Val loss: 0.5486 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:28, 10.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 31/55 \t Batch 49/50 \t Loss 0.5789 \t Running Acc 0.699 \t Total Acc 0.699 \t Avg Batch Time 10.1761\n",
      "Time: train: 508.81 \t Train loss 0.5789 \t Train acc: 0.6987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5656 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5711\n",
      "Epoch 30/55 finished.\n",
      "Train time: 508.81 \t Val time 39.28\n",
      "Train loss 0.5789 \t Train acc: 0.6987\n",
      "Val loss: 0.5479 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:28, 10.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 32/55 \t Batch 49/50 \t Loss 0.5669 \t Running Acc 0.723 \t Total Acc 0.723 \t Avg Batch Time 10.1799\n",
      "Time: train: 508.99 \t Train loss 0.5669 \t Train acc: 0.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5658 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5769\n",
      "Epoch 31/55 finished.\n",
      "Train time: 508.99 \t Val time 39.42\n",
      "Train loss 0.5669 \t Train acc: 0.7225\n",
      "Val loss: 0.5481 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:27, 10.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 33/55 \t Batch 49/50 \t Loss 0.5720 \t Running Acc 0.715 \t Total Acc 0.715 \t Avg Batch Time 10.1505\n",
      "Time: train: 507.52 \t Train loss 0.5720 \t Train acc: 0.7150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5701\n",
      "Epoch 32/55 finished.\n",
      "Train time: 507.52 \t Val time 39.25\n",
      "Train loss 0.5720 \t Train acc: 0.7150\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:29, 10.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 34/55 \t Batch 49/50 \t Loss 0.5676 \t Running Acc 0.725 \t Total Acc 0.725 \t Avg Batch Time 10.1896\n",
      "Time: train: 509.48 \t Train loss 0.5676 \t Train acc: 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5795\n",
      "Epoch 33/55 finished.\n",
      "Train time: 509.48 \t Val time 39.49\n",
      "Train loss 0.5676 \t Train acc: 0.7250\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:29, 10.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 35/55 \t Batch 49/50 \t Loss 0.5786 \t Running Acc 0.694 \t Total Acc 0.694 \t Avg Batch Time 10.1878\n",
      "Time: train: 509.39 \t Train loss 0.5786 \t Train acc: 0.6937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5821\n",
      "Epoch 34/55 finished.\n",
      "Train time: 509.39 \t Val time 39.55\n",
      "Train loss 0.5786 \t Train acc: 0.6937\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:28, 10.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 36/55 \t Batch 49/50 \t Loss 0.5783 \t Running Acc 0.699 \t Total Acc 0.699 \t Avg Batch Time 10.1797\n",
      "Time: train: 508.99 \t Train loss 0.5783 \t Train acc: 0.6987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5722\n",
      "Epoch 35/55 finished.\n",
      "Train time: 508.99 \t Val time 39.30\n",
      "Train loss 0.5783 \t Train acc: 0.6987\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:27, 10.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 37/55 \t Batch 49/50 \t Loss 0.5660 \t Running Acc 0.720 \t Total Acc 0.720 \t Avg Batch Time 10.1567\n",
      "Time: train: 507.84 \t Train loss 0.5660 \t Train acc: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5832\n",
      "Epoch 36/55 finished.\n",
      "Train time: 507.84 \t Val time 39.58\n",
      "Train loss 0.5660 \t Train acc: 0.7200\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:27, 10.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 38/55 \t Batch 49/50 \t Loss 0.5637 \t Running Acc 0.721 \t Total Acc 0.721 \t Avg Batch Time 10.1580\n",
      "Time: train: 507.90 \t Train loss 0.5637 \t Train acc: 0.7212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5748\n",
      "Epoch 37/55 finished.\n",
      "Train time: 507.90 \t Val time 39.37\n",
      "Train loss 0.5637 \t Train acc: 0.7212\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:26, 10.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 39/55 \t Batch 49/50 \t Loss 0.5715 \t Running Acc 0.719 \t Total Acc 0.719 \t Avg Batch Time 10.1301\n",
      "Time: train: 506.50 \t Train loss 0.5715 \t Train acc: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5766\n",
      "Epoch 38/55 finished.\n",
      "Train time: 506.50 \t Val time 39.42\n",
      "Train loss 0.5715 \t Train acc: 0.7188\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:27, 10.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 40/55 \t Batch 49/50 \t Loss 0.5701 \t Running Acc 0.723 \t Total Acc 0.723 \t Avg Batch Time 10.1414\n",
      "Time: train: 507.07 \t Train loss 0.5701 \t Train acc: 0.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5734\n",
      "Epoch 39/55 finished.\n",
      "Train time: 507.07 \t Val time 39.34\n",
      "Train loss 0.5701 \t Train acc: 0.7225\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:28, 10.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 41/55 \t Batch 49/50 \t Loss 0.5745 \t Running Acc 0.704 \t Total Acc 0.704 \t Avg Batch Time 10.1617\n",
      "Time: train: 508.08 \t Train loss 0.5745 \t Train acc: 0.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5698\n",
      "Epoch 40/55 finished.\n",
      "Train time: 508.08 \t Val time 39.24\n",
      "Train loss 0.5745 \t Train acc: 0.7037\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:24, 10.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 42/55 \t Batch 49/50 \t Loss 0.5712 \t Running Acc 0.723 \t Total Acc 0.723 \t Avg Batch Time 10.0958\n",
      "Time: train: 504.79 \t Train loss 0.5712 \t Train acc: 0.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5650\n",
      "Epoch 41/55 finished.\n",
      "Train time: 504.79 \t Val time 39.13\n",
      "Train loss 0.5712 \t Train acc: 0.7225\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:24, 10.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 43/55 \t Batch 49/50 \t Loss 0.5712 \t Running Acc 0.713 \t Total Acc 0.713 \t Avg Batch Time 10.0920\n",
      "Time: train: 504.60 \t Train loss 0.5712 \t Train acc: 0.7125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5510\n",
      "Epoch 42/55 finished.\n",
      "Train time: 504.60 \t Val time 38.78\n",
      "Train loss 0.5712 \t Train acc: 0.7125\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:21, 10.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 44/55 \t Batch 49/50 \t Loss 0.5651 \t Running Acc 0.721 \t Total Acc 0.721 \t Avg Batch Time 10.0397\n",
      "Time: train: 501.99 \t Train loss 0.5651 \t Train acc: 0.7212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5560\n",
      "Epoch 43/55 finished.\n",
      "Train time: 501.99 \t Val time 38.90\n",
      "Train loss 0.5651 \t Train acc: 0.7212\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:23, 10.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 45/55 \t Batch 49/50 \t Loss 0.5685 \t Running Acc 0.728 \t Total Acc 0.728 \t Avg Batch Time 10.0730\n",
      "Time: train: 503.65 \t Train loss 0.5685 \t Train acc: 0.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5566\n",
      "Epoch 44/55 finished.\n",
      "Train time: 503.65 \t Val time 38.91\n",
      "Train loss 0.5685 \t Train acc: 0.7275\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:23, 10.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 46/55 \t Batch 49/50 \t Loss 0.5733 \t Running Acc 0.723 \t Total Acc 0.723 \t Avg Batch Time 10.0624\n",
      "Time: train: 503.12 \t Train loss 0.5733 \t Train acc: 0.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5542\n",
      "Epoch 45/55 finished.\n",
      "Train time: 503.12 \t Val time 38.85\n",
      "Train loss 0.5733 \t Train acc: 0.7225\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:24, 10.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 47/55 \t Batch 49/50 \t Loss 0.5738 \t Running Acc 0.726 \t Total Acc 0.726 \t Avg Batch Time 10.0959\n",
      "Time: train: 504.80 \t Train loss 0.5738 \t Train acc: 0.7262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5620\n",
      "Epoch 46/55 finished.\n",
      "Train time: 504.80 \t Val time 39.05\n",
      "Train loss 0.5738 \t Train acc: 0.7262\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:25, 10.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 48/55 \t Batch 49/50 \t Loss 0.5612 \t Running Acc 0.733 \t Total Acc 0.733 \t Avg Batch Time 10.1178\n",
      "Time: train: 505.89 \t Train loss 0.5612 \t Train acc: 0.7325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:39,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5621\n",
      "Epoch 47/55 finished.\n",
      "Train time: 505.89 \t Val time 39.05\n",
      "Train loss 0.5612 \t Train acc: 0.7325\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:23, 10.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 49/55 \t Batch 49/50 \t Loss 0.5725 \t Running Acc 0.734 \t Total Acc 0.734 \t Avg Batch Time 10.0659\n",
      "Time: train: 503.29 \t Train loss 0.5725 \t Train acc: 0.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5470\n",
      "Epoch 48/55 finished.\n",
      "Train time: 503.29 \t Val time 38.67\n",
      "Train loss 0.5725 \t Train acc: 0.7338\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:22, 10.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 50/55 \t Batch 49/50 \t Loss 0.5797 \t Running Acc 0.709 \t Total Acc 0.709 \t Avg Batch Time 10.0491\n",
      "Time: train: 502.46 \t Train loss 0.5797 \t Train acc: 0.7087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5514\n",
      "Epoch 49/55 finished.\n",
      "Train time: 502.46 \t Val time 38.78\n",
      "Train loss 0.5797 \t Train acc: 0.7087\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:22, 10.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 51/55 \t Batch 49/50 \t Loss 0.5620 \t Running Acc 0.750 \t Total Acc 0.750 \t Avg Batch Time 10.0518\n",
      "Time: train: 502.59 \t Train loss 0.5620 \t Train acc: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5583\n",
      "Epoch 50/55 finished.\n",
      "Train time: 502.59 \t Val time 38.96\n",
      "Train loss 0.5620 \t Train acc: 0.7500\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:20, 10.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 52/55 \t Batch 49/50 \t Loss 0.5694 \t Running Acc 0.719 \t Total Acc 0.719 \t Avg Batch Time 10.0071\n",
      "Time: train: 500.36 \t Train loss 0.5694 \t Train acc: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5454\n",
      "Epoch 51/55 finished.\n",
      "Train time: 500.36 \t Val time 38.63\n",
      "Train loss 0.5694 \t Train acc: 0.7188\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:20, 10.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 53/55 \t Batch 49/50 \t Loss 0.5697 \t Running Acc 0.734 \t Total Acc 0.734 \t Avg Batch Time 10.0040\n",
      "Time: train: 500.20 \t Train loss 0.5697 \t Train acc: 0.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5521\n",
      "Epoch 52/55 finished.\n",
      "Train time: 500.20 \t Val time 38.80\n",
      "Train loss 0.5697 \t Train acc: 0.7338\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:23, 10.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 54/55 \t Batch 49/50 \t Loss 0.5708 \t Running Acc 0.711 \t Total Acc 0.711 \t Avg Batch Time 10.0745\n",
      "Time: train: 503.72 \t Train loss 0.5708 \t Train acc: 0.7113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5563\n",
      "Epoch 53/55 finished.\n",
      "Train time: 503.72 \t Val time 38.91\n",
      "Train loss 0.5708 \t Train acc: 0.7113\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [08:19, 10.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 55/55 \t Batch 49/50 \t Loss 0.5661 \t Running Acc 0.751 \t Total Acc 0.751 \t Avg Batch Time 9.9979\n",
      "Time: train: 499.89 \t Train loss 0.5661 \t Train acc: 0.7512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:38,  5.56s/it]\n",
      "/tmp/ipykernel_17/813438993.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model = torch.load(os.path.join(model_path, \"best-val-model.pt\"), map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.5657 \t Running Acc 2.714 \t Total Acc 0.760 \t Avg Batch Time 1.5577\n",
      "Epoch 54/55 finished.\n",
      "Train time: 499.89 \t Val time 38.94\n",
      "Train loss 0.5661 \t Train acc: 0.7512\n",
      "Val loss: 0.5480 \t Val acc: 0.7600\n",
      "Best val acc: 0.8000 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:37,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> test \t Loss 0.6478 \t Running Acc 2.643 \t Total Acc 0.740 \t Avg Batch Time 1.5170\n",
      "Final  tensor([[0.0000, 0.5111, 0.4889],\n",
      "        [1.0000, 0.4862, 0.5138],\n",
      "        [0.0000, 0.5829, 0.4171],\n",
      "        [0.0000, 0.6354, 0.3646],\n",
      "        [0.0000, 0.5900, 0.4100],\n",
      "        [1.0000, 0.4917, 0.5083],\n",
      "        [0.0000, 0.5217, 0.4783],\n",
      "        [0.0000, 0.5087, 0.4913],\n",
      "        [1.0000, 0.4910, 0.5090],\n",
      "        [1.0000, 0.4882, 0.5118],\n",
      "        [1.0000, 0.4882, 0.5118],\n",
      "        [0.0000, 0.5634, 0.4366],\n",
      "        [0.0000, 0.5957, 0.4043],\n",
      "        [1.0000, 0.5478, 0.4522],\n",
      "        [0.0000, 0.5470, 0.4530],\n",
      "        [1.0000, 0.5743, 0.4257],\n",
      "        [1.0000, 0.5929, 0.4071],\n",
      "        [1.0000, 0.5348, 0.4652],\n",
      "        [0.0000, 0.5666, 0.4334],\n",
      "        [0.0000, 0.5606, 0.4394],\n",
      "        [1.0000, 0.5456, 0.4544],\n",
      "        [1.0000, 0.4533, 0.5467],\n",
      "        [0.0000, 0.4742, 0.5258],\n",
      "        [0.0000, 0.6269, 0.3731],\n",
      "        [0.0000, 0.5390, 0.4610],\n",
      "        [1.0000, 0.5501, 0.4499],\n",
      "        [1.0000, 0.4728, 0.5272],\n",
      "        [0.0000, 0.6075, 0.3925],\n",
      "        [0.0000, 0.5377, 0.4623],\n",
      "        [0.0000, 0.6160, 0.3840],\n",
      "        [0.0000, 0.5812, 0.4188],\n",
      "        [0.0000, 0.5691, 0.4309],\n",
      "        [0.0000, 0.5587, 0.4413],\n",
      "        [1.0000, 0.5353, 0.4647],\n",
      "        [1.0000, 0.4808, 0.5192],\n",
      "        [1.0000, 0.4897, 0.5103],\n",
      "        [0.0000, 0.5585, 0.4415],\n",
      "        [1.0000, 0.4593, 0.5407],\n",
      "        [0.0000, 0.5690, 0.4310],\n",
      "        [0.0000, 0.5933, 0.4067],\n",
      "        [0.0000, 0.5628, 0.4372],\n",
      "        [1.0000, 0.4770, 0.5230],\n",
      "        [1.0000, 0.4503, 0.5497],\n",
      "        [0.0000, 0.5259, 0.4741],\n",
      "        [0.0000, 0.5633, 0.4367],\n",
      "        [1.0000, 0.5053, 0.4947],\n",
      "        [1.0000, 0.4804, 0.5196],\n",
      "        [1.0000, 0.5362, 0.4638],\n",
      "        [1.0000, 0.4478, 0.5522],\n",
      "        [0.0000, 0.5599, 0.4401],\n",
      "        [0.0000, 0.5506, 0.4494],\n",
      "        [1.0000, 0.4964, 0.5036],\n",
      "        [1.0000, 0.5425, 0.4575],\n",
      "        [1.0000, 0.4827, 0.5173],\n",
      "        [1.0000, 0.4746, 0.5254],\n",
      "        [1.0000, 0.4585, 0.5415],\n",
      "        [0.0000, 0.5354, 0.4646],\n",
      "        [0.0000, 0.6216, 0.3784],\n",
      "        [0.0000, 0.6289, 0.3711],\n",
      "        [0.0000, 0.5156, 0.4844],\n",
      "        [0.0000, 0.5353, 0.4647],\n",
      "        [1.0000, 0.4681, 0.5319],\n",
      "        [1.0000, 0.5445, 0.4555],\n",
      "        [1.0000, 0.5695, 0.4305],\n",
      "        [1.0000, 0.5195, 0.4805],\n",
      "        [1.0000, 0.4866, 0.5134],\n",
      "        [1.0000, 0.5940, 0.4060],\n",
      "        [0.0000, 0.5878, 0.4122],\n",
      "        [1.0000, 0.4894, 0.5106],\n",
      "        [0.0000, 0.5482, 0.4518],\n",
      "        [1.0000, 0.4794, 0.5206],\n",
      "        [1.0000, 0.4613, 0.5387],\n",
      "        [1.0000, 0.5057, 0.4943],\n",
      "        [0.0000, 0.5601, 0.4399],\n",
      "        [1.0000, 0.5032, 0.4968],\n",
      "        [1.0000, 0.4664, 0.5336],\n",
      "        [1.0000, 0.4827, 0.5173],\n",
      "        [0.0000, 0.5276, 0.4724],\n",
      "        [1.0000, 0.5205, 0.4795],\n",
      "        [0.0000, 0.5506, 0.4494],\n",
      "        [1.0000, 0.4831, 0.5169],\n",
      "        [1.0000, 0.5107, 0.4893],\n",
      "        [1.0000, 0.5812, 0.4188],\n",
      "        [0.0000, 0.5729, 0.4271],\n",
      "        [0.0000, 0.5500, 0.4500],\n",
      "        [1.0000, 0.5226, 0.4774],\n",
      "        [1.0000, 0.4917, 0.5083],\n",
      "        [0.0000, 0.5823, 0.4177],\n",
      "        [1.0000, 0.5578, 0.4422],\n",
      "        [1.0000, 0.4893, 0.5107],\n",
      "        [1.0000, 0.4879, 0.5121],\n",
      "        [1.0000, 0.4693, 0.5307],\n",
      "        [0.0000, 0.5883, 0.4117],\n",
      "        [1.0000, 0.5119, 0.4881],\n",
      "        [1.0000, 0.5186, 0.4814],\n",
      "        [0.0000, 0.6230, 0.3770],\n",
      "        [1.0000, 0.5185, 0.4815],\n",
      "        [1.0000, 0.5384, 0.4616],\n",
      "        [1.0000, 0.4903, 0.5097],\n",
      "        [0.0000, 0.6319, 0.3681]])\n",
      "Test: Loss 0.6465 \t Acc 0.7400 \t AUC: 0.8738 \t 1/eB 0.3: inf \t 1/eB 0.5: 44.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_17/813438993.py:155: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  'test_auc': auc, 'test_1/eB_0.3':1./eB[0],'test_1/eB_0.5':1./eB[1]}\n",
      "/tmp/ipykernel_17/813438993.py:158: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  % (test_res['loss'], test_res['acc'], auc, 1./eB[0], 1./eB[1]))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import json, time\n",
    "# import utils_lorentz\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    N_EPOCHS = 55 # 60\n",
    "\n",
    "    model_path = \"models/LieEQGNN/\"\n",
    "    log_path = \"logs/LieEQGNN/\"\n",
    "    # utils_lorentz.args_init(args)\n",
    "\n",
    "    ### set random seed\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    ### initialize cpu\n",
    "    # dist.init_process_group(backend='nccl')\n",
    "    device = 'cpu' #torch.device(\"cuda\")\n",
    "    dtype = torch.float32\n",
    "\n",
    "    ### load data\n",
    "    # dataloaders = retrieve_dataloaders( batch_size,\n",
    "    #                                     num_data=100000, # use all data\n",
    "    #                                     cache_dir=\"datasets/QMLHEP/quark_gluons/\",\n",
    "    #                                     num_workers=0,\n",
    "    #                                     use_one_hot=True)\n",
    "\n",
    "    model = LieEQGNN(n_scalar = 1, n_hidden = 4, n_class = 2,\\\n",
    "                       dropout = 0.2, n_layers = 1,\\\n",
    "                       c_weight = 1e-3)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    ### print model and dataset information\n",
    "    # if (args.local_rank == 0):\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"Model Size:\", pytorch_total_params)\n",
    "    for (split, dataloader) in dataloaders.items():\n",
    "        print(f\" {split} samples: {len(dataloader.dataset)}\")\n",
    "\n",
    "    ### optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "\n",
    "    ### lr scheduler\n",
    "    base_scheduler = CosineAnnealingWarmRestarts(optimizer, 4, 2, verbose = False)\n",
    "    lr_scheduler = GradualWarmupScheduler(optimizer, multiplier=1,\\\n",
    "                                                warmup_epoch=5,\\\n",
    "                                                after_scheduler=base_scheduler) ## warmup\n",
    "\n",
    "    ### loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    ### initialize logs\n",
    "    res = {'epochs': [], 'lr' : [],\\\n",
    "           'train_time': [], 'val_time': [],  'train_loss': [], 'val_loss': [],\\\n",
    "           'train_acc': [], 'val_acc': [], 'best_val': 0, 'best_epoch': 0}\n",
    "\n",
    "    ### training and testing\n",
    "    print(\"Training...\")\n",
    "    train(model, res, N_EPOCHS, model_path, log_path)\n",
    "    test(model, res, model_path, log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722f3d1",
   "metadata": {
    "papermill": {
     "duration": 0.287591,
     "end_time": "2024-10-25T17:35:22.982759",
     "exception": false,
     "start_time": "2024-10-25T17:35:22.695168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30205.10888,
   "end_time": "2024-10-25T17:35:26.276308",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-25T09:12:01.167428",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
